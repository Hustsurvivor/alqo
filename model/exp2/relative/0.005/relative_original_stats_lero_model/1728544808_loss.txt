Epoch: 0, training loss: 0.526792611231403
Epoch: 1, training loss: 0.4658343752927521
Epoch: 2, training loss: 0.4448842866338034
Epoch: 3, training loss: 0.4322191975143624
Epoch: 4, training loss: 0.4209310180660447
Epoch: 5, training loss: 0.41332667933433725
Epoch: 6, training loss: 0.40375388100086257
Epoch: 7, training loss: 0.3982363535126981
Epoch: 8, training loss: 0.39110390142329077
Epoch: 9, training loss: 0.38547904314107023
Epoch: 10, training loss: 0.379028317490305
Epoch: 11, training loss: 0.3746051580325995
Epoch: 12, training loss: 0.3694474373595106
Epoch: 13, training loss: 0.36455121160592124
Epoch: 14, training loss: 0.3593428277611129
Epoch: 15, training loss: 0.35520893729664227
Epoch: 16, training loss: 0.35084888095767613
Epoch: 17, training loss: 0.34706682238613096
Epoch: 18, training loss: 0.3429614870510859
Epoch: 19, training loss: 0.3397526345653474
Epoch: 20, training loss: 0.33597164216650793
Epoch: 21, training loss: 0.3316802947269947
Epoch: 22, training loss: 0.3295580070535086
Epoch: 23, training loss: 0.32620212297882084
Epoch: 24, training loss: 0.32336118862737484
Epoch: 25, training loss: 0.32074130033547893
Epoch: 26, training loss: 0.31699230425827607
Epoch: 27, training loss: 0.3153447303382625
Epoch: 28, training loss: 0.3124536329241168
Epoch: 29, training loss: 0.3083031623767452
Epoch: 30, training loss: 0.3056331787780846
Epoch: 31, training loss: 0.3034306680450228
Epoch: 32, training loss: 0.30159896660421576
Epoch: 33, training loss: 0.29883887915057245
Epoch: 34, training loss: 0.2970340570333176
Epoch: 35, training loss: 0.29517439350309954
Epoch: 36, training loss: 0.2929447373493232
Epoch: 37, training loss: 0.29048975492409246
Epoch: 38, training loss: 0.2884753713465165
Epoch: 39, training loss: 0.2852608826094334
Epoch: 40, training loss: 0.2841847317624654
Epoch: 41, training loss: 0.2814954501581043
Epoch: 42, training loss: 0.27988304962736255
Epoch: 43, training loss: 0.27829843590028214
Epoch: 44, training loss: 0.27621790951613395
Epoch: 45, training loss: 0.2749357905161618
Epoch: 46, training loss: 0.27263455934818576
Epoch: 47, training loss: 0.27167303468469745
Epoch: 48, training loss: 0.2681298700732325
Epoch: 49, training loss: 0.26833644683940544
Epoch: 50, training loss: 0.26557711071531936
Epoch: 51, training loss: 0.26399374400416287
Epoch: 52, training loss: 0.2627675613826009
Epoch: 53, training loss: 0.26115038991190076
Epoch: 54, training loss: 0.25939216707497037
Epoch: 55, training loss: 0.2588418844590734
Epoch: 56, training loss: 0.25798347273814964
Epoch: 57, training loss: 0.2559075934155074
Epoch: 58, training loss: 0.25512346364189936
Epoch: 59, training loss: 0.25434573977247404
Epoch: 60, training loss: 0.2521819766887275
Epoch: 61, training loss: 0.2505906530395673
Epoch: 62, training loss: 0.24873336745005759
Epoch: 63, training loss: 0.24835084106078895
Epoch: 64, training loss: 0.24683483187647556
Epoch: 65, training loss: 0.24541058289677609
Epoch: 66, training loss: 0.24516636171552564
Epoch: 67, training loss: 0.24239461543431332
Epoch: 68, training loss: 0.24254870639656695
Epoch: 69, training loss: 0.24159737636375278
Epoch: 70, training loss: 0.2404653450092305
Epoch: 71, training loss: 0.23820993331892776
Epoch: 72, training loss: 0.237807144512708
Epoch: 73, training loss: 0.237044156390838
Epoch: 74, training loss: 0.2374971270724979
Epoch: 75, training loss: 0.23511242813318925
Epoch: 76, training loss: 0.23465326878626702
Epoch: 77, training loss: 0.2342902428753825
Epoch: 78, training loss: 0.23151064563565824
Epoch: 79, training loss: 0.233277156452041
Epoch: 80, training loss: 0.23137159897613754
Epoch: 81, training loss: 0.22952736261438145
Epoch: 82, training loss: 0.22840585671825067
Epoch: 83, training loss: 0.2274710778711406
Epoch: 84, training loss: 0.2273132593935165
Epoch: 85, training loss: 0.22679602625048134
Epoch: 86, training loss: 0.22418542658168336
Epoch: 87, training loss: 0.22321549577869218
Epoch: 88, training loss: 0.22433937068571272
Epoch: 89, training loss: 0.2234024367034331
Epoch: 90, training loss: 0.22250897781428192
Epoch: 91, training loss: 0.22183909982627784
Epoch: 92, training loss: 0.22115414271664452
Epoch: 93, training loss: 0.22060327468019506
Epoch: 94, training loss: 0.22000601775550235
Epoch: 95, training loss: 0.21741570272648392
Epoch: 96, training loss: 0.2173975353813994
Epoch: 97, training loss: 0.21760584307125994
Epoch: 98, training loss: 0.21667254681417128
Epoch: 99, training loss: 0.21615536407277006
