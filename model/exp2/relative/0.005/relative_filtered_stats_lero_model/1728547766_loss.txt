Epoch: 0, training loss: 0.4875749706569369
Epoch: 1, training loss: 0.42552154655143026
Epoch: 2, training loss: 0.40690892264271794
Epoch: 3, training loss: 0.39299437179286856
Epoch: 4, training loss: 0.3846108736654056
Epoch: 5, training loss: 0.37511038126553964
Epoch: 6, training loss: 0.3659011956257753
Epoch: 7, training loss: 0.36053426538742306
Epoch: 8, training loss: 0.35352874992964695
Epoch: 9, training loss: 0.3485882177332481
Epoch: 10, training loss: 0.34234776152105306
Epoch: 11, training loss: 0.3367911670874114
Epoch: 12, training loss: 0.33181041511042725
Epoch: 13, training loss: 0.32845658592614413
Epoch: 14, training loss: 0.32209697979219754
Epoch: 15, training loss: 0.3181877112210709
Epoch: 16, training loss: 0.31308963961259056
Epoch: 17, training loss: 0.30883814940038024
Epoch: 18, training loss: 0.3054348513435943
Epoch: 19, training loss: 0.30117649457639895
Epoch: 20, training loss: 0.29667751567223294
Epoch: 21, training loss: 0.2930850502678196
Epoch: 22, training loss: 0.29120654865843737
Epoch: 23, training loss: 0.28709701677304283
Epoch: 24, training loss: 0.28309273497472787
Epoch: 25, training loss: 0.28011927206652176
Epoch: 26, training loss: 0.27685054553774247
Epoch: 27, training loss: 0.27578808311984454
Epoch: 28, training loss: 0.2718172182635988
Epoch: 29, training loss: 0.26792765606258917
Epoch: 30, training loss: 0.26658491448088817
Epoch: 31, training loss: 0.2625439960159006
Epoch: 32, training loss: 0.26054190602005517
Epoch: 33, training loss: 0.25719341788179845
Epoch: 34, training loss: 0.25666203951299205
Epoch: 35, training loss: 0.25384332374672786
Epoch: 36, training loss: 0.25167606065166087
Epoch: 37, training loss: 0.24966129938925752
Epoch: 38, training loss: 0.2475034834289528
Epoch: 39, training loss: 0.24550647958502914
Epoch: 40, training loss: 0.24417427801086528
Epoch: 41, training loss: 0.24302718442685803
Epoch: 42, training loss: 0.24024080971249823
Epoch: 43, training loss: 0.23792763398095734
Epoch: 44, training loss: 0.23533977525840702
Epoch: 45, training loss: 0.232093538660877
Epoch: 46, training loss: 0.23207015225938254
Epoch: 47, training loss: 0.2303108134737711
Epoch: 48, training loss: 0.22869401791767238
Epoch: 49, training loss: 0.22656964608451258
Epoch: 50, training loss: 0.22344180206172592
Epoch: 51, training loss: 0.22280165432381352
Epoch: 52, training loss: 0.22246160051290453
Epoch: 53, training loss: 0.22011266393377052
Epoch: 54, training loss: 0.2191095976896541
Epoch: 55, training loss: 0.21696083834887323
Epoch: 56, training loss: 0.21658134600701398
Epoch: 57, training loss: 0.21537206148070384
Epoch: 58, training loss: 0.21412535280106718
Epoch: 59, training loss: 0.21264140012296393
Epoch: 60, training loss: 0.20951242012848506
Epoch: 61, training loss: 0.2094065959340016
Epoch: 62, training loss: 0.20717977778599178
Epoch: 63, training loss: 0.2085515684553003
Epoch: 64, training loss: 0.20704568321159617
Epoch: 65, training loss: 0.2061683558432762
Epoch: 66, training loss: 0.2033481810925216
Epoch: 67, training loss: 0.2029888725180811
Epoch: 68, training loss: 0.20219051156141585
Epoch: 69, training loss: 0.20217331531926305
Epoch: 70, training loss: 0.2008901402699131
Epoch: 71, training loss: 0.19878182002242972
Epoch: 72, training loss: 0.19903568269593153
Epoch: 73, training loss: 0.19680175165037067
Epoch: 74, training loss: 0.1988778691909714
Epoch: 75, training loss: 0.19539167021275308
Epoch: 76, training loss: 0.19391377661420905
Epoch: 77, training loss: 0.1940921989825898
Epoch: 78, training loss: 0.19351274790904271
Epoch: 79, training loss: 0.19176508248710986
Epoch: 80, training loss: 0.19251656219002697
Epoch: 81, training loss: 0.19109350366804403
Epoch: 82, training loss: 0.1880431695288183
Epoch: 83, training loss: 0.1883733947776852
Epoch: 84, training loss: 0.1892434206725729
Epoch: 85, training loss: 0.18554576280001137
Epoch: 86, training loss: 0.18685681717719954
Epoch: 87, training loss: 0.1860364524057702
Epoch: 88, training loss: 0.18434246516934805
Epoch: 89, training loss: 0.1846211031719139
Epoch: 90, training loss: 0.18325049198189913
Epoch: 91, training loss: 0.18333544232555862
Epoch: 92, training loss: 0.18263086617279062
Epoch: 93, training loss: 0.18192469144689113
Epoch: 94, training loss: 0.18031421086353322
Epoch: 95, training loss: 0.1795027349340477
Epoch: 96, training loss: 0.18017029163543935
Epoch: 97, training loss: 0.17718977492769494
Epoch: 98, training loss: 0.1790437219415436
Epoch: 99, training loss: 0.17708416707714206
