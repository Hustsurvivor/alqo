train LeroModelPairWise
Epoch: 0, training loss: 0.6890603579170926
Epoch: 1, training loss: 0.6620030793421952
Epoch: 2, training loss: 0.617496652978307
Epoch: 3, training loss: 0.5769956649478609
Epoch: 4, training loss: 0.5409882272597591
Epoch: 5, training loss: 0.48297578741365554
Epoch: 6, training loss: 0.4316957801615089
Epoch: 7, training loss: 0.3844861334440903
Epoch: 8, training loss: 0.37525847938137574
Epoch: 9, training loss: 0.3350731492903545
Epoch: 10, training loss: 0.30155942586136164
Epoch: 11, training loss: 0.2851905798958712
Epoch: 12, training loss: 0.250160618483744
Epoch: 13, training loss: 0.23556391106235064
Epoch: 14, training loss: 0.22745459464704942
Epoch: 15, training loss: 0.2005846825592752
Epoch: 16, training loss: 0.19587764769698482
Epoch: 17, training loss: 0.2018387509327491
Epoch: 18, training loss: 0.19577323690015086
Epoch: 19, training loss: 0.18441052908873734
Epoch: 20, training loss: 0.15623934819386437
Epoch: 21, training loss: 0.16736810938992672
Epoch: 22, training loss: 0.15901964633118545
Epoch: 23, training loss: 0.15486379560411503
Epoch: 24, training loss: 0.14066843219757036
Epoch: 25, training loss: 0.13273817268880655
Epoch: 26, training loss: 0.13161246775698035
Epoch: 27, training loss: 0.12819382459605527
Epoch: 28, training loss: 0.13005577741436322
Epoch: 29, training loss: 0.0993281732510563
Epoch: 30, training loss: 0.10883099037615977
Epoch: 31, training loss: 0.10207445411316562
Epoch: 32, training loss: 0.12137139820431556
Epoch: 33, training loss: 0.1219063110477754
Epoch: 34, training loss: 0.09965476998424903
Epoch: 35, training loss: 0.0870333342178254
Epoch: 36, training loss: 0.10192037801132052
Epoch: 37, training loss: 0.10284252453547492
Epoch: 38, training loss: 0.09459450883580284
Epoch: 39, training loss: 0.08875686427523316
Epoch: 40, training loss: 0.08069619020271167
Epoch: 41, training loss: 0.08021280275136188
Epoch: 42, training loss: 0.07858654823660344
Epoch: 43, training loss: 0.06661301903310252
Epoch: 44, training loss: 0.06421191025646508
Epoch: 45, training loss: 0.07930212995061275
Epoch: 46, training loss: 0.08512712403698906
Epoch: 47, training loss: 0.09927779022201585
Epoch: 48, training loss: 0.07447903948113271
Epoch: 49, training loss: 0.09693461817505865
Epoch: 50, training loss: 0.10313814172205284
Epoch: 51, training loss: 0.0996888848602928
Epoch: 52, training loss: 0.0816191279368416
Epoch: 53, training loss: 0.07881537295715013
Epoch: 54, training loss: 0.06990559905985635
Epoch: 55, training loss: 0.06723934737616784
Epoch: 56, training loss: 0.05637427106597415
Epoch: 57, training loss: 0.05689817908212404
Epoch: 58, training loss: 0.047845606744056156
Epoch: 59, training loss: 0.049825894761204664
Epoch: 60, training loss: 0.061405195011132244
Epoch: 61, training loss: 0.061783665570339444
Epoch: 62, training loss: 0.048469425064886926
Epoch: 63, training loss: 0.06766252008924578
Epoch: 64, training loss: 0.04480696900312272
Epoch: 65, training loss: 0.05216418899831879
Epoch: 66, training loss: 0.04942988130506639
Epoch: 67, training loss: 0.08462558897732163
Epoch: 68, training loss: 0.0686789855675631
Epoch: 69, training loss: 0.06146433376238712
Epoch: 70, training loss: 0.05401269139215458
Epoch: 71, training loss: 0.0515269830642142
Epoch: 72, training loss: 0.054079938497971415
Epoch: 73, training loss: 0.07156726642147906
Epoch: 74, training loss: 0.04752793026109514
Epoch: 75, training loss: 0.055464097427475684
Epoch: 76, training loss: 0.04933162911745265
Epoch: 77, training loss: 0.06248126967076796
Epoch: 78, training loss: 0.07315945211875444
Epoch: 79, training loss: 0.06184319538882905
Epoch: 80, training loss: 0.05229704937294443
Epoch: 81, training loss: 0.03830067166495438
Epoch: 82, training loss: 0.04320343038588539
Epoch: 83, training loss: 0.04613344353471514
Epoch: 84, training loss: 0.04833536907884423
Epoch: 85, training loss: 0.037408165149974
Epoch: 86, training loss: 0.052522861308815165
Epoch: 87, training loss: 0.04198112402495237
Epoch: 88, training loss: 0.046996956789422305
Epoch: 89, training loss: 0.034879578121566675
Epoch: 90, training loss: 0.03841693708857878
Epoch: 91, training loss: 0.04587008801953484
Epoch: 92, training loss: 0.03270157002142172
Epoch: 93, training loss: 0.032928172991854285
Epoch: 94, training loss: 0.030468722098569986
Epoch: 95, training loss: 0.04481291338651814
Epoch: 96, training loss: 0.04314391253316103
Epoch: 97, training loss: 0.03107895054513389
Epoch: 98, training loss: 0.030212790923112128
Epoch: 99, training loss: 0.03879109489610274
