train LeroModelPairWise
Epoch: 0, training loss: 0.691615770814912
Epoch: 1, training loss: 0.655778587916224
Epoch: 2, training loss: 0.6286881318240256
Epoch: 3, training loss: 0.5663005934870807
Epoch: 4, training loss: 0.511888771405305
Epoch: 5, training loss: 0.45051571115433203
Epoch: 6, training loss: 0.4266818809870057
Epoch: 7, training loss: 0.38380911938800605
Epoch: 8, training loss: 0.35743652668574777
Epoch: 9, training loss: 0.31365206398109063
Epoch: 10, training loss: 0.2879603768466449
Epoch: 11, training loss: 0.2727131033378553
Epoch: 12, training loss: 0.2513028432867672
Epoch: 13, training loss: 0.2200711531612192
Epoch: 14, training loss: 0.20801640008728411
Epoch: 15, training loss: 0.19491461077320493
Epoch: 16, training loss: 0.21272558507521366
Epoch: 17, training loss: 0.17604824812058764
Epoch: 18, training loss: 0.16865659218275428
Epoch: 19, training loss: 0.1722461093527226
Epoch: 20, training loss: 0.13943928184427998
Epoch: 21, training loss: 0.12130822993787618
Epoch: 22, training loss: 0.1347754826028256
Epoch: 23, training loss: 0.14767932075785417
Epoch: 24, training loss: 0.12567299899431575
Epoch: 25, training loss: 0.11532984020931375
Epoch: 26, training loss: 0.12383561773925059
Epoch: 27, training loss: 0.1453025176673925
Epoch: 28, training loss: 0.1394800313409532
Epoch: 29, training loss: 0.11705722327728711
Epoch: 30, training loss: 0.10915606949430584
Epoch: 31, training loss: 0.1138538482761267
Epoch: 32, training loss: 0.09997715878834183
Epoch: 33, training loss: 0.08321837340286972
Epoch: 34, training loss: 0.07831095162227933
Epoch: 35, training loss: 0.08665954763950824
Epoch: 36, training loss: 0.08413662032906188
Epoch: 37, training loss: 0.07934065358685184
Epoch: 38, training loss: 0.0791063253386337
Epoch: 39, training loss: 0.0845543097125227
Epoch: 40, training loss: 0.08740714822319226
Epoch: 41, training loss: 0.08388157788063344
Epoch: 42, training loss: 0.07910321983710084
Epoch: 43, training loss: 0.06721224280753028
Epoch: 44, training loss: 0.06784338430188797
Epoch: 45, training loss: 0.06863182010929404
Epoch: 46, training loss: 0.06475930483080775
Epoch: 47, training loss: 0.0805375335728847
Epoch: 48, training loss: 0.0746396721004981
Epoch: 49, training loss: 0.06998316923505785
Epoch: 50, training loss: 0.06728273804164912
Epoch: 51, training loss: 0.05964144380328733
Epoch: 52, training loss: 0.07559693489290904
Epoch: 53, training loss: 0.07602505205610785
Epoch: 54, training loss: 0.06245985713658736
Epoch: 55, training loss: 0.07271277518724532
Epoch: 56, training loss: 0.05263426881414106
Epoch: 57, training loss: 0.0682143408862352
Epoch: 58, training loss: 0.07263332443878882
Epoch: 59, training loss: 0.0712179198634663
Epoch: 60, training loss: 0.058981796582756874
Epoch: 61, training loss: 0.05916131388675453
Epoch: 62, training loss: 0.05906751035445955
Epoch: 63, training loss: 0.06704011270329195
Epoch: 64, training loss: 0.04888070224852327
Epoch: 65, training loss: 0.05207075325447699
Epoch: 66, training loss: 0.05472036601354299
Epoch: 67, training loss: 0.04471142267277442
Epoch: 68, training loss: 0.04574476339995456
Epoch: 69, training loss: 0.059137203370367826
Epoch: 70, training loss: 0.05254377096057691
Epoch: 71, training loss: 0.03358570347393207
Epoch: 72, training loss: 0.036179477253979214
Epoch: 73, training loss: 0.03429870530356317
Epoch: 74, training loss: 0.048429909581667964
Epoch: 75, training loss: 0.04972177679003172
Epoch: 76, training loss: 0.027937005141370614
Epoch: 77, training loss: 0.03908991890726381
Epoch: 78, training loss: 0.03691623009898806
Epoch: 79, training loss: 0.026420594115753888
Epoch: 80, training loss: 0.03360238887491551
Epoch: 81, training loss: 0.041653537767502816
Epoch: 82, training loss: 0.05176254375749654
Epoch: 83, training loss: 0.04225494944824014
Epoch: 84, training loss: 0.053071080297830954
Epoch: 85, training loss: 0.043853269283965886
Epoch: 86, training loss: 0.05263413075750712
Epoch: 87, training loss: 0.046813681036736866
Epoch: 88, training loss: 0.05984334397430456
Epoch: 89, training loss: 0.04475801455835705
Epoch: 90, training loss: 0.05914971268266158
Epoch: 91, training loss: 0.05150817558835694
Epoch: 92, training loss: 0.0614687061674403
Epoch: 93, training loss: 0.05374273778600943
Epoch: 94, training loss: 0.04251809505065043
Epoch: 95, training loss: 0.040916635026432197
Epoch: 96, training loss: 0.030663423802883123
Epoch: 97, training loss: 0.04452072213770994
Epoch: 98, training loss: 0.0369125965972838
Epoch: 99, training loss: 0.049507909474494745
