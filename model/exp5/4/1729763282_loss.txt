train LeroModelPairWise
Epoch: 0, training loss: 0.6894815229166448
Epoch: 1, training loss: 0.6321137667150601
Epoch: 2, training loss: 0.6064998987230887
Epoch: 3, training loss: 0.578619618558746
Epoch: 4, training loss: 0.5907437364739165
Epoch: 5, training loss: 0.5814280221206298
Epoch: 6, training loss: 0.5585351497649275
Epoch: 7, training loss: 0.5400612512500773
Epoch: 8, training loss: 0.5115601318057624
Epoch: 9, training loss: 0.48571805402850804
Epoch: 10, training loss: 0.4652512933331607
Epoch: 11, training loss: 0.4545115832353502
Epoch: 12, training loss: 0.4395246328768892
Epoch: 13, training loss: 0.41487684026057564
Epoch: 14, training loss: 0.4118778998290238
Epoch: 15, training loss: 0.4025163336525133
Epoch: 16, training loss: 0.39529126764230976
Epoch: 17, training loss: 0.3792182090672947
Epoch: 18, training loss: 0.36679082769309274
Epoch: 19, training loss: 0.3650967900913313
Epoch: 20, training loss: 0.34864174540737153
Epoch: 21, training loss: 0.3355105655906209
Epoch: 22, training loss: 0.3480696505924404
Epoch: 23, training loss: 0.34127029763509736
Epoch: 24, training loss: 0.319864275254746
Epoch: 25, training loss: 0.31296200946551106
Epoch: 26, training loss: 0.34493476823686314
Epoch: 27, training loss: 0.318739633956474
Epoch: 28, training loss: 0.31067097306892516
Epoch: 29, training loss: 0.29423743291777027
Epoch: 30, training loss: 0.2725462000755463
Epoch: 31, training loss: 0.29586049727262786
Epoch: 32, training loss: 0.2918075099897099
Epoch: 33, training loss: 0.257512246750118
Epoch: 34, training loss: 0.3106725306905526
Epoch: 35, training loss: 0.28482302625766437
Epoch: 36, training loss: 0.2912728229582575
Epoch: 37, training loss: 0.26620031091243884
Epoch: 38, training loss: 0.2748132905834137
Epoch: 39, training loss: 0.2547930384998016
Epoch: 40, training loss: 0.251890119879522
Epoch: 41, training loss: 0.25889651137252345
Epoch: 42, training loss: 0.3128302512604447
Epoch: 43, training loss: 0.26837318071331984
Epoch: 44, training loss: 0.22214775639906006
Epoch: 45, training loss: 0.2318368056405772
Epoch: 46, training loss: 0.21405721004211398
Epoch: 47, training loss: 0.2428279074195152
Epoch: 48, training loss: 0.22960781492389035
Epoch: 49, training loss: 0.22661388488350473
Epoch: 50, training loss: 0.27507566552233736
Epoch: 51, training loss: 0.22941903024247312
Epoch: 52, training loss: 0.225665547931021
Epoch: 53, training loss: 0.2316568142337622
Epoch: 54, training loss: 0.22574420371445011
Epoch: 55, training loss: 0.2235350046228488
Epoch: 56, training loss: 0.20925846870235756
Epoch: 57, training loss: 0.22386325034904633
Epoch: 58, training loss: 0.26998678254562786
Epoch: 59, training loss: 0.2105741047998283
Epoch: 60, training loss: 0.21347231661114527
Epoch: 61, training loss: 0.21680218301571821
Epoch: 62, training loss: 0.196115106659711
Epoch: 63, training loss: 0.20936744467268673
Epoch: 64, training loss: 0.22302250883593933
Epoch: 65, training loss: 0.21886720189633513
Epoch: 66, training loss: 0.2311819858467877
Epoch: 67, training loss: 0.22346457958639912
Epoch: 68, training loss: 0.2046223747702299
Epoch: 69, training loss: 0.1998594499358617
Epoch: 70, training loss: 0.2057024531139845
Epoch: 71, training loss: 0.2344206127623449
Epoch: 72, training loss: 0.18834167115185388
Epoch: 73, training loss: 0.22245680524798372
Epoch: 74, training loss: 0.27350754974743313
Epoch: 75, training loss: 0.21391364668769672
Epoch: 76, training loss: 0.28302929230824314
Epoch: 77, training loss: 0.23979626649587596
Epoch: 78, training loss: 0.22271249122144432
Epoch: 79, training loss: 0.19520141306763336
Epoch: 80, training loss: 0.19511083806555088
Epoch: 81, training loss: 0.18665276202823392
Epoch: 82, training loss: 0.18836767989677894
Epoch: 83, training loss: 0.16118431374807116
Epoch: 84, training loss: 0.18447047629816782
Epoch: 85, training loss: 0.2042587324393247
Epoch: 86, training loss: 0.19245748121007675
Epoch: 87, training loss: 0.19113815605231088
Epoch: 88, training loss: 0.19269848455341929
Epoch: 89, training loss: 0.20444882425587543
Epoch: 90, training loss: 0.15215291481689663
Epoch: 91, training loss: 0.12776505190298645
Epoch: 92, training loss: 0.11370993282266663
Epoch: 93, training loss: 0.11587977583824643
Epoch: 94, training loss: 0.11075251615000804
Epoch: 95, training loss: 0.11907654158815763
Epoch: 96, training loss: 0.09903810913269116
Epoch: 97, training loss: 0.09882323247819412
Epoch: 98, training loss: 0.08522882590478376
Epoch: 99, training loss: 0.09551200111027897
Epoch: 100, training loss: 0.09250481585457147
Epoch: 101, training loss: 0.09084545362449482
Epoch: 102, training loss: 0.09732725327009346
Epoch: 103, training loss: 0.08794434728863769
Epoch: 104, training loss: 0.0899972968062761
Epoch: 105, training loss: 0.08425383141293076
Epoch: 106, training loss: 0.07759122564598897
Epoch: 107, training loss: 0.0756294442934031
Epoch: 108, training loss: 0.07696210390866753
Epoch: 109, training loss: 0.07718301906379647
Epoch: 110, training loss: 0.0736038497598075
Epoch: 111, training loss: 0.07751314992889625
Epoch: 112, training loss: 0.07097699182209936
Epoch: 113, training loss: 0.07949089817686344
Epoch: 114, training loss: 0.07740394169067467
Epoch: 115, training loss: 0.07818490786375362
Epoch: 116, training loss: 0.07690969104456606
Epoch: 117, training loss: 0.0807585774548854
Epoch: 118, training loss: 0.07023985673419147
Epoch: 119, training loss: 0.0687917854250889
