train LeroModelPairWise
Epoch: 0, training loss: 0.6687012199419861
Epoch: 1, training loss: 0.6292424049374291
Epoch: 2, training loss: 0.6067411999383949
Epoch: 3, training loss: 0.5729252324203055
Epoch: 4, training loss: 0.5761863285117256
Epoch: 5, training loss: 0.5315706240254168
Epoch: 6, training loss: 0.5022526248579741
Epoch: 7, training loss: 0.4921304651813368
Epoch: 8, training loss: 0.49243587900304675
Epoch: 9, training loss: 0.4765107136800164
Epoch: 10, training loss: 0.44666851427385046
Epoch: 11, training loss: 0.43645657173026003
Epoch: 12, training loss: 0.4211102684491394
Epoch: 13, training loss: 0.4073282286692319
Epoch: 14, training loss: 0.38990946623330025
Epoch: 15, training loss: 0.3883965446000186
Epoch: 16, training loss: 0.36516352475300345
Epoch: 17, training loss: 0.39292972114928243
Epoch: 18, training loss: 0.36811432430511193
Epoch: 19, training loss: 0.35847225629388974
Epoch: 20, training loss: 0.3362859462519374
Epoch: 21, training loss: 0.347526344155838
Epoch: 22, training loss: 0.3382170040338019
Epoch: 23, training loss: 0.3310380021602144
Epoch: 24, training loss: 0.3140347312729483
Epoch: 25, training loss: 0.31486259805752026
Epoch: 26, training loss: 0.3163461528897044
Epoch: 27, training loss: 0.31665850560618
Epoch: 28, training loss: 0.29769421071787366
Epoch: 29, training loss: 0.3070388957557247
Epoch: 30, training loss: 0.3102110333924724
Epoch: 31, training loss: 0.29749261137821525
Epoch: 32, training loss: 0.30005864376223723
Epoch: 33, training loss: 0.2717653627360828
Epoch: 34, training loss: 0.2750719132518602
Epoch: 35, training loss: 0.27581741592648884
Epoch: 36, training loss: 0.28890011293001333
Epoch: 37, training loss: 0.2635550154467505
Epoch: 38, training loss: 0.30667747492525216
Epoch: 39, training loss: 0.2716600591324468
Epoch: 40, training loss: 0.27318271888486795
Epoch: 41, training loss: 0.24719461883457003
Epoch: 42, training loss: 0.23419256986108236
Epoch: 43, training loss: 0.27306705666965014
Epoch: 44, training loss: 0.2682932535603638
Epoch: 45, training loss: 0.2574013038361175
Epoch: 46, training loss: 0.25284982185876287
Epoch: 47, training loss: 0.2485547669651811
Epoch: 48, training loss: 0.23076958882849205
Epoch: 49, training loss: 0.25684717745436564
Epoch: 50, training loss: 0.24036848794609636
Epoch: 51, training loss: 0.21950014401705206
Epoch: 52, training loss: 0.22771153300762245
Epoch: 53, training loss: 0.23876506787411209
Epoch: 54, training loss: 0.22827774722194807
Epoch: 55, training loss: 0.23894547908885
Epoch: 56, training loss: 0.2398873978507934
Epoch: 57, training loss: 0.2113875403574291
Epoch: 58, training loss: 0.23874126280646749
Epoch: 59, training loss: 0.23066451145966557
Epoch: 60, training loss: 0.23103476134633347
Epoch: 61, training loss: 0.23651072961620437
Epoch: 62, training loss: 0.21498658824551284
Epoch: 63, training loss: 0.2092725482247185
Epoch: 64, training loss: 0.22258415320544014
Epoch: 65, training loss: 0.20357820181786176
Epoch: 66, training loss: 0.24123711373666779
Epoch: 67, training loss: 0.22018859194487317
Epoch: 68, training loss: 0.19491767473703636
Epoch: 69, training loss: 0.1963357619900539
Epoch: 70, training loss: 0.2167553010421742
Epoch: 71, training loss: 0.2139560576001467
Epoch: 72, training loss: 0.20110194485380217
Epoch: 73, training loss: 0.1924731947698627
Epoch: 74, training loss: 0.19820782440801876
Epoch: 75, training loss: 0.1893974193479401
Epoch: 76, training loss: 0.1908658148926551
Epoch: 77, training loss: 0.17898483849878555
Epoch: 78, training loss: 0.1883031779134511
Epoch: 79, training loss: 0.1863927818814015
Epoch: 80, training loss: 0.2184106471170881
Epoch: 81, training loss: 0.19093557744035636
Epoch: 82, training loss: 0.18693817751098277
Epoch: 83, training loss: 0.20229299043332508
Epoch: 84, training loss: 0.17663538179669627
Epoch: 85, training loss: 0.19016435081714114
Epoch: 86, training loss: 0.2083585177589704
Epoch: 87, training loss: 0.18772218135392804
Epoch: 88, training loss: 0.20150007720385232
Epoch: 89, training loss: 0.1491579888213117
Epoch: 90, training loss: 0.1460644295747565
Epoch: 91, training loss: 0.1219378851201764
Epoch: 92, training loss: 0.11404023424472032
Epoch: 93, training loss: 0.11150062573598583
Epoch: 94, training loss: 0.09330009498609311
Epoch: 95, training loss: 0.09933240050847737
Epoch: 96, training loss: 0.09741002401082975
Epoch: 97, training loss: 0.09416832196855161
Epoch: 98, training loss: 0.09693610133289628
Epoch: 99, training loss: 0.09284974560556401
Epoch: 100, training loss: 0.08012188515254205
Epoch: 101, training loss: 0.08296217799627846
Epoch: 102, training loss: 0.0829178498261424
Epoch: 103, training loss: 0.08701927414670108
Epoch: 104, training loss: 0.08399948797958041
Epoch: 105, training loss: 0.08066094962749586
Epoch: 106, training loss: 0.08541684806530193
Epoch: 107, training loss: 0.07271635394862426
Epoch: 108, training loss: 0.08208278732403715
Epoch: 109, training loss: 0.06699341018370487
Epoch: 110, training loss: 0.06755771804746363
Epoch: 111, training loss: 0.06790912950437096
Epoch: 112, training loss: 0.07973296228076854
Epoch: 113, training loss: 0.0742061528477145
Epoch: 114, training loss: 0.07696044824772831
Epoch: 115, training loss: 0.0687288461248446
Epoch: 116, training loss: 0.06430408976652235
Epoch: 117, training loss: 0.06589203427187122
Epoch: 118, training loss: 0.08403965342037263
Epoch: 119, training loss: 0.07056126105754627
