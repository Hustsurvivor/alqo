train LeroModelPairWise
Epoch: 0, training loss: 0.6838072950721855
Epoch: 1, training loss: 0.6364801821750768
Epoch: 2, training loss: 0.6160619848809411
Epoch: 3, training loss: 0.5854975478449839
Epoch: 4, training loss: 0.557164035357217
Epoch: 5, training loss: 0.5432694354102765
Epoch: 6, training loss: 0.5122629148459364
Epoch: 7, training loss: 0.5123014816967952
Epoch: 8, training loss: 0.48882044786160683
Epoch: 9, training loss: 0.4709313184197353
Epoch: 10, training loss: 0.4985482093589831
Epoch: 11, training loss: 0.45225671939115836
Epoch: 12, training loss: 0.43793937621009055
Epoch: 13, training loss: 0.40508637799114566
Epoch: 14, training loss: 0.3993902367847427
Epoch: 15, training loss: 0.39473405648319243
Epoch: 16, training loss: 0.3864180191548381
Epoch: 17, training loss: 0.3834699339703034
Epoch: 18, training loss: 0.38489091081677845
Epoch: 19, training loss: 0.3968939234395578
Epoch: 20, training loss: 0.355145862968931
Epoch: 21, training loss: 0.33242989008175167
Epoch: 22, training loss: 0.32981160849101393
Epoch: 23, training loss: 0.31251547125372553
Epoch: 24, training loss: 0.31407436464312394
Epoch: 25, training loss: 0.30045672229120673
Epoch: 26, training loss: 0.30399487760063537
Epoch: 27, training loss: 0.29572510736525
Epoch: 28, training loss: 0.34622900318716426
Epoch: 29, training loss: 0.3054659367668814
Epoch: 30, training loss: 0.28985143719756423
Epoch: 31, training loss: 0.26969071200516864
Epoch: 32, training loss: 0.28831553498665463
Epoch: 33, training loss: 0.2594181968043748
Epoch: 34, training loss: 0.26139352792233844
Epoch: 35, training loss: 0.2795913622757879
Epoch: 36, training loss: 0.2817531097349492
Epoch: 37, training loss: 0.24154444460177252
Epoch: 38, training loss: 0.2622281487528127
Epoch: 39, training loss: 0.2601574771582698
Epoch: 40, training loss: 0.29999014799273976
Epoch: 41, training loss: 0.23929313828791424
Epoch: 42, training loss: 0.24630021966258184
Epoch: 43, training loss: 0.24279198583176453
Epoch: 44, training loss: 0.20463129091034185
Epoch: 45, training loss: 0.1966577875331244
Epoch: 46, training loss: 0.21206093212821545
Epoch: 47, training loss: 0.2079781037092284
Epoch: 48, training loss: 0.23800740723842423
Epoch: 49, training loss: 0.2295411642849494
Epoch: 50, training loss: 0.20881103062846834
Epoch: 51, training loss: 0.19810687513751493
Epoch: 52, training loss: 0.1870984445972796
Epoch: 53, training loss: 0.1986503082127092
Epoch: 54, training loss: 0.191938927624091
Epoch: 55, training loss: 0.20905271185725902
Epoch: 56, training loss: 0.17912609975809302
Epoch: 57, training loss: 0.19199055080645042
Epoch: 58, training loss: 0.19678078219988548
Epoch: 59, training loss: 0.22762064925886943
Epoch: 60, training loss: 0.21328832316410623
Epoch: 61, training loss: 0.2026939389156362
Epoch: 62, training loss: 0.19216249364837867
Epoch: 63, training loss: 0.2066771548830523
Epoch: 64, training loss: 0.18934140120492
Epoch: 65, training loss: 0.18729044220933697
Epoch: 66, training loss: 0.1962540158694133
Epoch: 67, training loss: 0.18965050337131745
Epoch: 68, training loss: 0.18587579853566583
Epoch: 69, training loss: 0.1461477988723749
Epoch: 70, training loss: 0.15572242330954666
Epoch: 71, training loss: 0.20565484011192034
Epoch: 72, training loss: 0.14990995661800624
Epoch: 73, training loss: 0.17276690404376469
Epoch: 74, training loss: 0.17238636576094893
Epoch: 75, training loss: 0.15289359968558555
Epoch: 76, training loss: 0.15416574528026492
Epoch: 77, training loss: 0.18223894568231372
Epoch: 78, training loss: 0.15744884771086481
Epoch: 79, training loss: 0.16446919148686348
Epoch: 80, training loss: 0.15661850953000298
Epoch: 81, training loss: 0.15488837109086678
Epoch: 82, training loss: 0.15984627159652096
Epoch: 83, training loss: 0.1461383951104076
Epoch: 84, training loss: 0.21669219266747416
Epoch: 85, training loss: 0.15208022787467002
Epoch: 86, training loss: 0.17097409788396167
Epoch: 87, training loss: 0.1588378195850041
Epoch: 88, training loss: 0.1455941592545664
Epoch: 89, training loss: 0.16440605949670717
Epoch: 90, training loss: 0.1451776790303752
Epoch: 91, training loss: 0.10192724358470712
Epoch: 92, training loss: 0.07883219338513017
Epoch: 93, training loss: 0.08067049304482853
Epoch: 94, training loss: 0.07885970993420016
Epoch: 95, training loss: 0.07445552248594808
Epoch: 96, training loss: 0.06728295358550129
Epoch: 97, training loss: 0.06624943106397922
Epoch: 98, training loss: 0.06951680411089783
Epoch: 99, training loss: 0.06149054065534692
Epoch: 100, training loss: 0.06161729625384847
Epoch: 101, training loss: 0.053402105936112346
Epoch: 102, training loss: 0.050543029917604225
Epoch: 103, training loss: 0.06272374793235248
Epoch: 104, training loss: 0.05041067887280342
Epoch: 105, training loss: 0.047142837265479
Epoch: 106, training loss: 0.06086568429722092
Epoch: 107, training loss: 0.05625175908902719
Epoch: 108, training loss: 0.048577143582937854
Epoch: 109, training loss: 0.05179179985752705
Epoch: 110, training loss: 0.04442452336853466
Epoch: 111, training loss: 0.04604465246168717
Epoch: 112, training loss: 0.046166779133743646
Epoch: 113, training loss: 0.04443375431731006
Epoch: 114, training loss: 0.042509130635727484
Epoch: 115, training loss: 0.03288670959008961
Epoch: 116, training loss: 0.04349514241192598
Epoch: 117, training loss: 0.04626145205739154
Epoch: 118, training loss: 0.039201099926870736
Epoch: 119, training loss: 0.04125869882681602
