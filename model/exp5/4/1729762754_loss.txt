train LeroModelPairWise
Epoch: 0, training loss: 0.668158553819122
Epoch: 1, training loss: 0.594327939332533
Epoch: 2, training loss: 0.531465412971833
Epoch: 3, training loss: 0.5179963400433986
Epoch: 4, training loss: 0.4942544151346969
Epoch: 5, training loss: 0.46224597620079233
Epoch: 6, training loss: 0.43883123909348926
Epoch: 7, training loss: 0.4280755260470792
Epoch: 8, training loss: 0.4257831323595882
Epoch: 9, training loss: 0.388920028546141
Epoch: 10, training loss: 0.38566680449597107
Epoch: 11, training loss: 0.39248878360266215
Epoch: 12, training loss: 0.36567208749969543
Epoch: 13, training loss: 0.35545740605865844
Epoch: 14, training loss: 0.38058124963753925
Epoch: 15, training loss: 0.3579935252205002
Epoch: 16, training loss: 0.3341055008416323
Epoch: 17, training loss: 0.3163601958102816
Epoch: 18, training loss: 0.324983655827804
Epoch: 19, training loss: 0.2930276979797443
Epoch: 20, training loss: 0.2827808032980172
Epoch: 21, training loss: 0.28254811723782325
Epoch: 22, training loss: 0.3048956200887107
Epoch: 23, training loss: 0.3024260886512655
Epoch: 24, training loss: 0.28112340472426955
Epoch: 25, training loss: 0.2737751411068408
Epoch: 26, training loss: 0.2547730196519867
Epoch: 27, training loss: 0.2561341349078296
Epoch: 28, training loss: 0.2608234694114001
Epoch: 29, training loss: 0.2953336847985137
Epoch: 30, training loss: 0.2529362383915514
Epoch: 31, training loss: 0.27233829197566656
Epoch: 32, training loss: 0.24899452323723775
Epoch: 33, training loss: 0.2275459643408051
Epoch: 34, training loss: 0.22306432288211464
Epoch: 35, training loss: 0.2219694074713169
Epoch: 36, training loss: 0.2357767899791183
Epoch: 37, training loss: 0.2277632100285081
Epoch: 38, training loss: 0.23361148097741136
Epoch: 39, training loss: 0.2325796458337197
Epoch: 40, training loss: 0.1842495127256179
Epoch: 41, training loss: 0.21826659228735373
Epoch: 42, training loss: 0.20362925076152497
Epoch: 43, training loss: 0.2016088868645794
Epoch: 44, training loss: 0.19853434848790308
Epoch: 45, training loss: 0.19872108962897383
Epoch: 46, training loss: 0.20374415785371702
Epoch: 47, training loss: 0.2136117412770736
Epoch: 48, training loss: 0.1738533172563619
Epoch: 49, training loss: 0.1905538235050874
Epoch: 50, training loss: 0.2064416459271082
Epoch: 51, training loss: 0.22899075762031643
Epoch: 52, training loss: 0.20424091773921849
Epoch: 53, training loss: 0.17375061835058692
Epoch: 54, training loss: 0.17055037111496213
Epoch: 55, training loss: 0.16400890233343876
Epoch: 56, training loss: 0.19166753127313513
Epoch: 57, training loss: 0.1781404812416867
Epoch: 58, training loss: 0.16289699913741507
Epoch: 59, training loss: 0.18544976803141508
Epoch: 60, training loss: 0.19952447927272168
Epoch: 61, training loss: 0.17098384886509227
Epoch: 62, training loss: 0.1631214204315939
Epoch: 63, training loss: 0.16813998533793376
Epoch: 64, training loss: 0.16680818217540805
Epoch: 65, training loss: 0.1580087939583815
Epoch: 66, training loss: 0.1420114471940746
Epoch: 67, training loss: 0.16836856780532294
Epoch: 68, training loss: 0.1808233170529416
Epoch: 69, training loss: 0.14854658919577482
Epoch: 70, training loss: 0.18484715777224683
Epoch: 71, training loss: 0.1532846781047768
Epoch: 72, training loss: 0.17886545636238446
Epoch: 73, training loss: 0.15796062151294435
Epoch: 74, training loss: 0.1411615434138079
Epoch: 75, training loss: 0.15395910214943054
Epoch: 76, training loss: 0.1750463082883283
Epoch: 77, training loss: 0.14378425652434648
Epoch: 78, training loss: 0.14412006373362576
Epoch: 79, training loss: 0.17837355033498914
Epoch: 80, training loss: 0.1529001217605349
Epoch: 81, training loss: 0.1615148937224099
Epoch: 82, training loss: 0.1358111006883036
Epoch: 83, training loss: 0.14851156028062312
Epoch: 84, training loss: 0.14075058055748835
Epoch: 85, training loss: 0.14369758055564993
Epoch: 86, training loss: 0.16039833291433436
Epoch: 87, training loss: 0.13479966612257416
Epoch: 88, training loss: 0.13308500844678137
Epoch: 89, training loss: 0.16894248169478635
Epoch: 90, training loss: 0.11106304744702797
Epoch: 91, training loss: 0.08301428152349198
Epoch: 92, training loss: 0.07571099679983452
Epoch: 93, training loss: 0.06828903635006522
Epoch: 94, training loss: 0.07142141638343531
Epoch: 95, training loss: 0.0710657553624298
Epoch: 96, training loss: 0.05407611925274358
Epoch: 97, training loss: 0.0522824723788834
Epoch: 98, training loss: 0.05651622731414412
Epoch: 99, training loss: 0.05949676449812721
Epoch: 100, training loss: 0.0512859622076339
Epoch: 101, training loss: 0.04495995571810331
Epoch: 102, training loss: 0.043876007059227604
Epoch: 103, training loss: 0.046457258820357235
Epoch: 104, training loss: 0.04545461345823949
Epoch: 105, training loss: 0.054164965205640236
Epoch: 106, training loss: 0.059951579878560673
Epoch: 107, training loss: 0.04184930047294527
Epoch: 108, training loss: 0.046392645902290496
Epoch: 109, training loss: 0.04230850658179207
Epoch: 110, training loss: 0.04167130782152566
Epoch: 111, training loss: 0.04192168875710475
Epoch: 112, training loss: 0.04186595424039486
Epoch: 113, training loss: 0.05313022992263868
Epoch: 114, training loss: 0.03471240428555033
Epoch: 115, training loss: 0.03339346336041694
Epoch: 116, training loss: 0.04034781188832817
Epoch: 117, training loss: 0.036411615071743286
Epoch: 118, training loss: 0.03468480862101675
Epoch: 119, training loss: 0.03093415445375268
