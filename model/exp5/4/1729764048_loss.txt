train LeroModelPairWise
Epoch: 0, training loss: 0.6754291366806906
Epoch: 1, training loss: 0.626496500733574
Epoch: 2, training loss: 0.5795726524832755
Epoch: 3, training loss: 0.5514643145738141
Epoch: 4, training loss: 0.5261835043733516
Epoch: 5, training loss: 0.49955245186644764
Epoch: 6, training loss: 0.4762506267723694
Epoch: 7, training loss: 0.45299059218968324
Epoch: 8, training loss: 0.4477217045482194
Epoch: 9, training loss: 0.43474843134620955
Epoch: 10, training loss: 0.4011857945683313
Epoch: 11, training loss: 0.41348332439883556
Epoch: 12, training loss: 0.3782407652181672
Epoch: 13, training loss: 0.39785239148314716
Epoch: 14, training loss: 0.38443359881177036
Epoch: 15, training loss: 0.3510113865682844
Epoch: 16, training loss: 0.34914156848595673
Epoch: 17, training loss: 0.3381277786236097
Epoch: 18, training loss: 0.34145775496948244
Epoch: 19, training loss: 0.3300208917862026
Epoch: 20, training loss: 0.32646900790824546
Epoch: 21, training loss: 0.3015685247616472
Epoch: 22, training loss: 0.32063239528982623
Epoch: 23, training loss: 0.2988354839522026
Epoch: 24, training loss: 0.2903766470774342
Epoch: 25, training loss: 0.3047920910283763
Epoch: 26, training loss: 0.2827641363725914
Epoch: 27, training loss: 0.28465099146754985
Epoch: 28, training loss: 0.28546969898151564
Epoch: 29, training loss: 0.27751525609742494
Epoch: 30, training loss: 0.26361360285130975
Epoch: 31, training loss: 0.26846824625144194
Epoch: 32, training loss: 0.2747184915899622
Epoch: 33, training loss: 0.25047316612623355
Epoch: 34, training loss: 0.26439800451516576
Epoch: 35, training loss: 0.2404585338391256
Epoch: 36, training loss: 0.23555196860451455
Epoch: 37, training loss: 0.2579974337585502
Epoch: 38, training loss: 0.24690985301428262
Epoch: 39, training loss: 0.22811644650683768
Epoch: 40, training loss: 0.23686152409188968
Epoch: 41, training loss: 0.23526017145480582
Epoch: 42, training loss: 0.21996688553679103
Epoch: 43, training loss: 0.23690137687798243
Epoch: 44, training loss: 0.24196114783522527
Epoch: 45, training loss: 0.23249891497575023
Epoch: 46, training loss: 0.21490426111896976
Epoch: 47, training loss: 0.21819692994295734
Epoch: 48, training loss: 0.2237369136421995
Epoch: 49, training loss: 0.23527213663243876
Epoch: 50, training loss: 0.2308106575222109
Epoch: 51, training loss: 0.1998415076634598
Epoch: 52, training loss: 0.1986056918189408
Epoch: 53, training loss: 0.19926836406078732
Epoch: 54, training loss: 0.21403132465015315
Epoch: 55, training loss: 0.2057648843803872
Epoch: 56, training loss: 0.18838610544139708
Epoch: 57, training loss: 0.1790702856380881
Epoch: 58, training loss: 0.1751890270078553
Epoch: 59, training loss: 0.20906583825786432
Epoch: 60, training loss: 0.20573053217718698
Epoch: 61, training loss: 0.18729384426922172
Epoch: 62, training loss: 0.1929089027189499
Epoch: 63, training loss: 0.17123679636387132
Epoch: 64, training loss: 0.20058490291092776
Epoch: 65, training loss: 0.18943351962813282
Epoch: 66, training loss: 0.20525105500206753
Epoch: 67, training loss: 0.19047633767598734
Epoch: 68, training loss: 0.18224066762647204
Epoch: 69, training loss: 0.18239226414193818
Epoch: 70, training loss: 0.19639774051904146
Epoch: 71, training loss: 0.19260412249109218
Epoch: 72, training loss: 0.17778532502607522
Epoch: 73, training loss: 0.1593268790119965
Epoch: 74, training loss: 0.1640523716863794
Epoch: 75, training loss: 0.17474508334807662
Epoch: 76, training loss: 0.1727829167614099
Epoch: 77, training loss: 0.1564027871050623
Epoch: 78, training loss: 0.14737091153586532
Epoch: 79, training loss: 0.15032277264606855
Epoch: 80, training loss: 0.1454833274859992
Epoch: 81, training loss: 0.1553619971445755
Epoch: 82, training loss: 0.15360499007960235
Epoch: 83, training loss: 0.18603764143503873
Epoch: 84, training loss: 0.1710245514855291
Epoch: 85, training loss: 0.172919406621731
Epoch: 86, training loss: 0.15411446670911846
Epoch: 87, training loss: 0.1404982579486466
Epoch: 88, training loss: 0.15728154754501406
Epoch: 89, training loss: 0.15459054457204877
Epoch: 90, training loss: 0.12446572182194937
Epoch: 91, training loss: 0.083310384005903
Epoch: 92, training loss: 0.07562596993565117
Epoch: 93, training loss: 0.07165109293994625
Epoch: 94, training loss: 0.07086708026814603
Epoch: 95, training loss: 0.0651711907676382
Epoch: 96, training loss: 0.0600569703697286
Epoch: 97, training loss: 0.06524679887996325
Epoch: 98, training loss: 0.06301021918298987
Epoch: 99, training loss: 0.05362177690871526
Epoch: 100, training loss: 0.055448339110062195
Epoch: 101, training loss: 0.06988856419837519
Epoch: 102, training loss: 0.05997751227665731
Epoch: 103, training loss: 0.0523934572619881
Epoch: 104, training loss: 0.04613445731182219
Epoch: 105, training loss: 0.04978551396316188
Epoch: 106, training loss: 0.05109533690326639
Epoch: 107, training loss: 0.055716953795859836
Epoch: 108, training loss: 0.05723408795018547
Epoch: 109, training loss: 0.04655565511483966
Epoch: 110, training loss: 0.04286122708207715
Epoch: 111, training loss: 0.04519939436633031
Epoch: 112, training loss: 0.04997326671569285
Epoch: 113, training loss: 0.03935975421448639
Epoch: 114, training loss: 0.048429620826366454
Epoch: 115, training loss: 0.035451830729744255
Epoch: 116, training loss: 0.056402587727036525
Epoch: 117, training loss: 0.040374816995281775
Epoch: 118, training loss: 0.0411949673468312
Epoch: 119, training loss: 0.03747765518141471
