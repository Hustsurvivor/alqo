RelType :  {'Index Scan', 'Index Only Scan', 'Materialize', 'Merge Join', 'Sort', 'Nested Loop', 'Hash Join', 'Seq Scan', 'Hash', 'Aggregate'}
input_feature_dim: 26
Epoch 0 training loss: 0.6192688624811844
Epoch 1 training loss: 0.5448286079256908
Epoch 2 training loss: 0.5131966166196819
Epoch 3 training loss: 0.4903124576299455
Epoch 4 training loss: 0.47111314143975686
Epoch 5 training loss: 0.4510808748400493
Epoch 6 training loss: 0.44019325750216975
Epoch 7 training loss: 0.41526301841443863
Epoch 8 training loss: 0.40377293546699194
Epoch 9 training loss: 0.39108541009365316
Epoch 10 training loss: 0.3782691549831628
Epoch 11 training loss: 0.36125027869844717
Epoch 12 training loss: 0.3521605330228045
Epoch 13 training loss: 0.3458534241136025
Epoch 14 training loss: 0.33531108342851385
Epoch 15 training loss: 0.3218609261302285
Epoch 16 training loss: 0.31557941392833244
Epoch 17 training loss: 0.3115314056858531
Epoch 18 training loss: 0.3091284008130482
Epoch 19 training loss: 0.2880163712773901
Epoch 20 training loss: 0.28501735307000065
Epoch 21 training loss: 0.28385749362359547
Epoch 22 training loss: 0.2698474927981368
Epoch 23 training loss: 0.2674511147715709
Epoch 24 training loss: 0.2606935889491721
Epoch 25 training loss: 0.26250542768039015
Epoch 26 training loss: 0.24369340881567475
Epoch 27 training loss: 0.24392355896886764
Epoch 28 training loss: 0.23816347745602726
Epoch 29 training loss: 0.23402870715918364
Epoch 30 training loss: 0.23218483184896813
Epoch 31 training loss: 0.23140651846664853
Epoch 32 training loss: 0.22372165939038904
Epoch 33 training loss: 0.21532583576656106
Epoch 34 training loss: 0.21504692660974198
Epoch 35 training loss: 0.21341031340459982
Epoch 36 training loss: 0.21473490092216696
Epoch 37 training loss: 0.20805650960599859
Epoch 38 training loss: 0.2072663618850995
Epoch 39 training loss: 0.19538278245172944
Epoch 40 training loss: 0.198215434689006
Epoch 41 training loss: 0.19687472021642005
Epoch 42 training loss: 0.18779677762415176
Epoch 43 training loss: 0.18914721731795336
Epoch 44 training loss: 0.18403769668981523
Epoch 45 training loss: 0.18421985781400063
Epoch 46 training loss: 0.17812138156559867
Epoch 47 training loss: 0.18024372342961573
Epoch 48 training loss: 0.18162774212352706
Epoch 49 training loss: 0.16879115520956767
Epoch 50 training loss: 0.17695020431221545
Epoch 51 training loss: 0.17296829770535826
Epoch 52 training loss: 0.17521832962887895
Epoch 53 training loss: 0.16744227198864436
Epoch 54 training loss: 0.16650080708643272
Epoch 55 training loss: 0.16205557767686135
Epoch 56 training loss: 0.16600726211467898
Epoch 57 training loss: 0.16039630747855493
Epoch 58 training loss: 0.16259015722278636
Epoch 59 training loss: 0.16114376223811747
Epoch 60 training loss: 0.15430283128669425
Epoch 61 training loss: 0.15151958794923845
Epoch 62 training loss: 0.15083628965419746
Epoch 63 training loss: 0.15814222898271824
Epoch 64 training loss: 0.156193334143608
Epoch 65 training loss: 0.15139042801065256
Epoch 66 training loss: 0.14988947499908903
Epoch 67 training loss: 0.14585552702753188
Epoch 68 training loss: 0.153040533462056
Epoch 69 training loss: 0.1423770946902424
Epoch 70 training loss: 0.1450498131938446
Epoch 71 training loss: 0.13788986946110085
Epoch 72 training loss: 0.14235671429876304
Epoch 73 training loss: 0.14310824143569825
Epoch 74 training loss: 0.1408138119714139
Epoch 75 training loss: 0.14267151886070556
Epoch 76 training loss: 0.13918574570227998
Epoch 77 training loss: 0.1425667405733054
Epoch 78 training loss: 0.13748634262772677
Epoch 79 training loss: 0.14136526758354287
Epoch 80 training loss: 0.13592050108856005
Epoch 81 training loss: 0.12799452733429528
Epoch 82 training loss: 0.1301889420408592
Epoch 83 training loss: 0.12937839995371705
Epoch 84 training loss: 0.13726809174040905
Epoch 85 training loss: 0.12687561971746744
Epoch 86 training loss: 0.12736954142269527
Epoch 87 training loss: 0.13025812204938056
Epoch 88 training loss: 0.13004387689068014
Epoch 89 training loss: 0.13383856111342385
Epoch 90 training loss: 0.12861947586804126
Epoch 91 training loss: 0.12701926018407364
Epoch 92 training loss: 0.13125194424299852
Epoch 93 training loss: 0.124271995166817
Epoch 94 training loss: 0.12283395555709202
Epoch 95 training loss: 0.12005785704550823
Epoch 96 training loss: 0.12342082838777602
Epoch 97 training loss: 0.12629815299446182
Epoch 98 training loss: 0.11861100967148011
Epoch 99 training loss: 0.12277189214571814
training time: 495.8315532207489 batch size: 64
