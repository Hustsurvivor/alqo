train LeroModelPairWise
Epoch: 0, training loss: 0.6117947305028036
Epoch: 1, training loss: 0.5494301424190513
Epoch: 2, training loss: 0.5095018422421252
Epoch: 3, training loss: 0.48220714100860884
Epoch: 4, training loss: 0.4626518074688707
Epoch: 5, training loss: 0.44621753280062554
Epoch: 6, training loss: 0.42948813272615427
Epoch: 7, training loss: 0.41062720469885805
Epoch: 8, training loss: 0.4062498537278198
Epoch: 9, training loss: 0.3879394692063806
Epoch: 10, training loss: 0.37535944881750666
Epoch: 11, training loss: 0.36881691682802664
Epoch: 12, training loss: 0.3543438007634103
Epoch: 13, training loss: 0.3429065635433456
Epoch: 14, training loss: 0.34540040644912834
Epoch: 15, training loss: 0.33198295786099946
Epoch: 16, training loss: 0.31937299416267595
Epoch: 17, training loss: 0.3134476169464273
Epoch: 18, training loss: 0.3056888124094597
Epoch: 19, training loss: 0.29229166811313056
Epoch: 20, training loss: 0.29092658424534956
Epoch: 21, training loss: 0.284778502767603
Epoch: 22, training loss: 0.2733295692849783
Epoch: 23, training loss: 0.2739687928160195
Epoch: 24, training loss: 0.2608469487040868
Epoch: 25, training loss: 0.25896749129675767
Epoch: 26, training loss: 0.2583153057774676
Epoch: 27, training loss: 0.24959922114918584
Epoch: 28, training loss: 0.25158825610821656
Epoch: 29, training loss: 0.2426459372177978
Epoch: 30, training loss: 0.23878875397356913
Epoch: 31, training loss: 0.23996650858588492
Epoch: 32, training loss: 0.23163055881194358
Epoch: 33, training loss: 0.23610069351699348
Epoch: 34, training loss: 0.22603660619765914
Epoch: 35, training loss: 0.22450674205490523
Epoch: 36, training loss: 0.21643288138985736
Epoch: 37, training loss: 0.21820360992440854
Epoch: 38, training loss: 0.2142642605762531
Epoch: 39, training loss: 0.2132652695741309
Epoch: 40, training loss: 0.2069366723173624
Epoch: 41, training loss: 0.20643161922572537
Epoch: 42, training loss: 0.20330544016277083
Epoch: 43, training loss: 0.19778589032177296
Epoch: 44, training loss: 0.20041045924982775
Epoch: 45, training loss: 0.19470503008981985
Epoch: 46, training loss: 0.1958240942079066
Epoch: 47, training loss: 0.19227382598007078
Epoch: 48, training loss: 0.19468443170173153
Epoch: 49, training loss: 0.18973359009829352
Epoch: 50, training loss: 0.18422890666230302
Epoch: 51, training loss: 0.18375055451023586
Epoch: 52, training loss: 0.18630235774506626
Epoch: 53, training loss: 0.18685101329173426
Epoch: 54, training loss: 0.18114292482959463
Epoch: 55, training loss: 0.1804156341787224
Epoch: 56, training loss: 0.17844514739424078
Epoch: 57, training loss: 0.17960421768547077
Epoch: 58, training loss: 0.17015772376980243
Epoch: 59, training loss: 0.1814034563500226
Epoch: 60, training loss: 0.17210435214081407
Epoch: 61, training loss: 0.16622241816268402
Epoch: 62, training loss: 0.17068780017872848
Epoch: 63, training loss: 0.17229385072829756
Epoch: 64, training loss: 0.16271912932259966
Epoch: 65, training loss: 0.1653052910122565
Epoch: 66, training loss: 0.1648891125420848
Epoch: 67, training loss: 0.16552830689718248
Epoch: 68, training loss: 0.16639988813883924
Epoch: 69, training loss: 0.15760030779554723
Epoch: 70, training loss: 0.16230625645648247
Epoch: 71, training loss: 0.16022415511629798
Epoch: 72, training loss: 0.1631768170604252
Epoch: 73, training loss: 0.15659326907165558
Epoch: 74, training loss: 0.16042211248763374
Epoch: 75, training loss: 0.15112141739361717
Epoch: 76, training loss: 0.1529245156154946
Epoch: 77, training loss: 0.15609832492974465
Epoch: 78, training loss: 0.1554607829647245
Epoch: 79, training loss: 0.15217977021189502
Epoch: 80, training loss: 0.1537987843589704
Epoch: 81, training loss: 0.14998441778468097
Epoch: 82, training loss: 0.1502562764159068
Epoch: 83, training loss: 0.1538014379324241
Epoch: 84, training loss: 0.15446965961013714
Epoch: 85, training loss: 0.1509619539525164
Epoch: 86, training loss: 0.1441427300920761
Epoch: 87, training loss: 0.14340013107068914
Epoch: 88, training loss: 0.14826462438320626
Epoch: 89, training loss: 0.15192274005304274
Epoch: 90, training loss: 0.14478435049023503
Epoch: 91, training loss: 0.14429343228471794
Epoch: 92, training loss: 0.14082990371466997
Epoch: 93, training loss: 0.13948818093851972
Epoch: 94, training loss: 0.1416604150949298
Epoch: 95, training loss: 0.1409810200764479
Epoch: 96, training loss: 0.14098661677362287
Epoch: 97, training loss: 0.14061238464166623
Epoch: 98, training loss: 0.13946645467025073
Epoch: 99, training loss: 0.13593147754041543
