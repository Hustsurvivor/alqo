train LeroModelPairWise
Epoch: 0, training loss: 0.6092600026303763
Epoch: 1, training loss: 0.5431009156737722
Epoch: 2, training loss: 0.5166401908668372
Epoch: 3, training loss: 0.4879853849735073
Epoch: 4, training loss: 0.46641110850479983
Epoch: 5, training loss: 0.44437394733298524
Epoch: 6, training loss: 0.43220929191414476
Epoch: 7, training loss: 0.42066687849102696
Epoch: 8, training loss: 0.4102262387752484
Epoch: 9, training loss: 0.3875858713656893
Epoch: 10, training loss: 0.37904853078584216
Epoch: 11, training loss: 0.369432235770578
Epoch: 12, training loss: 0.352898212703559
Epoch: 13, training loss: 0.3453635682718644
Epoch: 14, training loss: 0.3341968842437761
Epoch: 15, training loss: 0.3263638537175066
Epoch: 16, training loss: 0.31536624035482946
Epoch: 17, training loss: 0.3076128873506086
Epoch: 18, training loss: 0.3041741909867489
Epoch: 19, training loss: 0.29301359068770483
Epoch: 20, training loss: 0.28283864903854994
Epoch: 21, training loss: 0.2833404394630979
Epoch: 22, training loss: 0.27675327549985096
Epoch: 23, training loss: 0.2646716478375295
Epoch: 24, training loss: 0.2613092648637207
Epoch: 25, training loss: 0.2564112947693816
Epoch: 26, training loss: 0.24865148712681404
Epoch: 27, training loss: 0.24398637907177026
Epoch: 28, training loss: 0.24595591394894986
Epoch: 29, training loss: 0.23063505242740043
Epoch: 30, training loss: 0.2288703413177679
Epoch: 31, training loss: 0.22737855220227332
Epoch: 32, training loss: 0.2232689607461165
Epoch: 33, training loss: 0.2262205095480865
Epoch: 34, training loss: 0.22196424135947657
Epoch: 35, training loss: 0.21828034575707636
Epoch: 36, training loss: 0.20818375126385
Epoch: 37, training loss: 0.20819370315750563
Epoch: 38, training loss: 0.20457862802108193
Epoch: 39, training loss: 0.19936523349105292
Epoch: 40, training loss: 0.1991544284263675
Epoch: 41, training loss: 0.19484905284180393
Epoch: 42, training loss: 0.19493693924738087
Epoch: 43, training loss: 0.19671317275517786
Epoch: 44, training loss: 0.1967034827901643
Epoch: 45, training loss: 0.1950442689753459
Epoch: 46, training loss: 0.18202734725144049
Epoch: 47, training loss: 0.1845191899297718
Epoch: 48, training loss: 0.1809490373418817
Epoch: 49, training loss: 0.17809581508221206
Epoch: 50, training loss: 0.18073627231161765
Epoch: 51, training loss: 0.17783707982405608
Epoch: 52, training loss: 0.17403732982282005
Epoch: 53, training loss: 0.17303998378279167
Epoch: 54, training loss: 0.17237306875944164
Epoch: 55, training loss: 0.17335399668651705
Epoch: 56, training loss: 0.17046274890813715
Epoch: 57, training loss: 0.1654732405522669
Epoch: 58, training loss: 0.16805851679833855
Epoch: 59, training loss: 0.1601777895886385
Epoch: 60, training loss: 0.1688214243983397
Epoch: 61, training loss: 0.1616046872596395
Epoch: 62, training loss: 0.1643139792436931
Epoch: 63, training loss: 0.16303635421728857
Epoch: 64, training loss: 0.15652476031043816
Epoch: 65, training loss: 0.15785778911777812
Epoch: 66, training loss: 0.1573044411512647
Epoch: 67, training loss: 0.15336241783497653
Epoch: 68, training loss: 0.15453647257009395
Epoch: 69, training loss: 0.15935464241548206
Epoch: 70, training loss: 0.15193860087263428
Epoch: 71, training loss: 0.15178385419282076
Epoch: 72, training loss: 0.14938547867941943
Epoch: 73, training loss: 0.14748737605354376
Epoch: 74, training loss: 0.1511206789830132
Epoch: 75, training loss: 0.15390001251882568
Epoch: 76, training loss: 0.1445903840896506
Epoch: 77, training loss: 0.14138495155931152
Epoch: 78, training loss: 0.1512608301697684
Epoch: 79, training loss: 0.14293599237350216
Epoch: 80, training loss: 0.14535300495760106
Epoch: 81, training loss: 0.14210892749572426
Epoch: 82, training loss: 0.13921820724338801
Epoch: 83, training loss: 0.13790224125634257
Epoch: 84, training loss: 0.1415249124414361
Epoch: 85, training loss: 0.14086525710814854
Epoch: 86, training loss: 0.14081916103669526
Epoch: 87, training loss: 0.13606562690245505
Epoch: 88, training loss: 0.13730954713880755
Epoch: 89, training loss: 0.13524454580703787
Epoch: 90, training loss: 0.13411267001740906
Epoch: 91, training loss: 0.1338242206755227
Epoch: 92, training loss: 0.13673588796844138
Epoch: 93, training loss: 0.13411271173229022
Epoch: 94, training loss: 0.13271876396655222
Epoch: 95, training loss: 0.13150033742571432
Epoch: 96, training loss: 0.1295701888562196
Epoch: 97, training loss: 0.12704055635758574
Epoch: 98, training loss: 0.13098292240401208
Epoch: 99, training loss: 0.12776346165580765
