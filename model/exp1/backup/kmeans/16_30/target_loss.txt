train LeroModelPairWise
Epoch: 0, training loss: 0.6242142103883969
Epoch: 1, training loss: 0.56518317673534
Epoch: 2, training loss: 0.5245763063351154
Epoch: 3, training loss: 0.5008333322948091
Epoch: 4, training loss: 0.47148446052344584
Epoch: 5, training loss: 0.45654483216062924
Epoch: 6, training loss: 0.4390743439918704
Epoch: 7, training loss: 0.4262955742557441
Epoch: 8, training loss: 0.4063708466549044
Epoch: 9, training loss: 0.4016550578597995
Epoch: 10, training loss: 0.3800035821657043
Epoch: 11, training loss: 0.3764617534824181
Epoch: 12, training loss: 0.36186973325481314
Epoch: 13, training loss: 0.35096343109151773
Epoch: 14, training loss: 0.33398457049380686
Epoch: 15, training loss: 0.3189843476946675
Epoch: 16, training loss: 0.3137820114973808
Epoch: 17, training loss: 0.30274911725353404
Epoch: 18, training loss: 0.2927155489632845
Epoch: 19, training loss: 0.29406383645467354
Epoch: 20, training loss: 0.27282279087194
Epoch: 21, training loss: 0.26844325913460093
Epoch: 22, training loss: 0.26731814925208963
Epoch: 23, training loss: 0.25739916067042407
Epoch: 24, training loss: 0.24651915420525322
Epoch: 25, training loss: 0.24555698737366907
Epoch: 26, training loss: 0.23733261970142971
Epoch: 27, training loss: 0.23140574813730302
Epoch: 28, training loss: 0.23272982818686708
Epoch: 29, training loss: 0.23341662412940717
Epoch: 30, training loss: 0.22280218148811753
Epoch: 31, training loss: 0.21942069169453246
Epoch: 32, training loss: 0.21733025275300083
Epoch: 33, training loss: 0.21408535071501367
Epoch: 34, training loss: 0.20837747662991069
Epoch: 35, training loss: 0.210477966766466
Epoch: 36, training loss: 0.19757262974539488
Epoch: 37, training loss: 0.20059732687472834
Epoch: 38, training loss: 0.20033382602776648
Epoch: 39, training loss: 0.18652891176622707
Epoch: 40, training loss: 0.19048519736732059
Epoch: 41, training loss: 0.18315716688651149
Epoch: 42, training loss: 0.19035530604599823
Epoch: 43, training loss: 0.181615262194791
Epoch: 44, training loss: 0.18241382827392524
Epoch: 45, training loss: 0.17684257891075314
Epoch: 46, training loss: 0.1781092002589563
Epoch: 47, training loss: 0.17271595011335433
Epoch: 48, training loss: 0.17549204978134889
Epoch: 49, training loss: 0.17389840486641067
Epoch: 50, training loss: 0.17336281609563728
Epoch: 51, training loss: 0.16781006341951932
Epoch: 52, training loss: 0.1670193648787128
Epoch: 53, training loss: 0.16275174590927274
Epoch: 54, training loss: 0.16490939162552953
Epoch: 55, training loss: 0.16861830300974606
Epoch: 56, training loss: 0.16131966013206353
Epoch: 57, training loss: 0.16200066965906895
Epoch: 58, training loss: 0.1594421655130201
Epoch: 59, training loss: 0.16488843048900126
Epoch: 60, training loss: 0.15650220448598415
Epoch: 61, training loss: 0.14940237585950167
Epoch: 62, training loss: 0.15432214787980103
Epoch: 63, training loss: 0.15585096323464379
Epoch: 64, training loss: 0.158373256404236
Epoch: 65, training loss: 0.15388976911765292
Epoch: 66, training loss: 0.14828212607744248
Epoch: 67, training loss: 0.1457924303329492
Epoch: 68, training loss: 0.14989761479489402
Epoch: 69, training loss: 0.1440396305198159
Epoch: 70, training loss: 0.14520525416595442
Epoch: 71, training loss: 0.14692866528615195
Epoch: 72, training loss: 0.14564620532722586
Epoch: 73, training loss: 0.14285965053663613
Epoch: 74, training loss: 0.13840592202536
Epoch: 75, training loss: 0.14144625259760782
Epoch: 76, training loss: 0.13595486997301268
Epoch: 77, training loss: 0.14112948402543501
Epoch: 78, training loss: 0.1365215887280297
Epoch: 79, training loss: 0.14027200861543554
Epoch: 80, training loss: 0.1362925840979492
Epoch: 81, training loss: 0.1388977126315317
Epoch: 82, training loss: 0.13235650163563312
Epoch: 83, training loss: 0.13501082388933527
Epoch: 84, training loss: 0.1303023501658162
Epoch: 85, training loss: 0.12953616775004728
Epoch: 86, training loss: 0.12905609529156298
Epoch: 87, training loss: 0.13101061686383977
Epoch: 88, training loss: 0.13165551286649152
Epoch: 89, training loss: 0.12675122449155993
Epoch: 90, training loss: 0.1283749444877435
Epoch: 91, training loss: 0.12837985621063733
Epoch: 92, training loss: 0.12747967674255625
Epoch: 93, training loss: 0.1269267395337623
Epoch: 94, training loss: 0.12456840657039638
Epoch: 95, training loss: 0.1241649587214145
Epoch: 96, training loss: 0.12312047500463377
Epoch: 97, training loss: 0.1249428846573983
Epoch: 98, training loss: 0.12263480095157397
Epoch: 99, training loss: 0.12734053380392707
