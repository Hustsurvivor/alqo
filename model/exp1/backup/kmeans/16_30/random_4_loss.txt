train LeroModelPairWise
Epoch: 0, training loss: 0.6172907254901573
Epoch: 1, training loss: 0.5543517024835806
Epoch: 2, training loss: 0.5112504906533076
Epoch: 3, training loss: 0.4945947986113866
Epoch: 4, training loss: 0.47049548435122407
Epoch: 5, training loss: 0.452457698587876
Epoch: 6, training loss: 0.43428864409449214
Epoch: 7, training loss: 0.42450786577970123
Epoch: 8, training loss: 0.4065475664723446
Epoch: 9, training loss: 0.3990146766686527
Epoch: 10, training loss: 0.3828907977475353
Epoch: 11, training loss: 0.3746895238472165
Epoch: 12, training loss: 0.362253791008997
Epoch: 13, training loss: 0.35229554594533785
Epoch: 14, training loss: 0.3425974935487233
Epoch: 15, training loss: 0.32613400668885445
Epoch: 16, training loss: 0.3223985464810001
Epoch: 17, training loss: 0.31687920198944924
Epoch: 18, training loss: 0.30565842838553253
Epoch: 19, training loss: 0.30109084753065146
Epoch: 20, training loss: 0.2898712435812444
Epoch: 21, training loss: 0.28488894171497114
Epoch: 22, training loss: 0.2802897155707339
Epoch: 23, training loss: 0.2763181151732573
Epoch: 24, training loss: 0.26773388433721435
Epoch: 25, training loss: 0.2562979108081627
Epoch: 26, training loss: 0.2632738120269006
Epoch: 27, training loss: 0.25005783276832105
Epoch: 28, training loss: 0.24730246606663378
Epoch: 29, training loss: 0.23896891987400917
Epoch: 30, training loss: 0.24547274060290786
Epoch: 31, training loss: 0.23051248987199174
Epoch: 32, training loss: 0.2303829577318127
Epoch: 33, training loss: 0.22577850314922718
Epoch: 34, training loss: 0.2257131468633475
Epoch: 35, training loss: 0.2180507488622017
Epoch: 36, training loss: 0.21547361147836294
Epoch: 37, training loss: 0.21906201406366926
Epoch: 38, training loss: 0.20533490941942675
Epoch: 39, training loss: 0.21368554705340329
Epoch: 40, training loss: 0.19978855448497415
Epoch: 41, training loss: 0.20171347828007785
Epoch: 42, training loss: 0.20423321128371283
Epoch: 43, training loss: 0.20128364316205566
Epoch: 44, training loss: 0.19479570764842455
Epoch: 45, training loss: 0.1955541107532654
Epoch: 46, training loss: 0.19090569130007198
Epoch: 47, training loss: 0.18645014572609864
Epoch: 48, training loss: 0.18643363100338958
Epoch: 49, training loss: 0.18615668216619274
Epoch: 50, training loss: 0.17968640953144835
Epoch: 51, training loss: 0.1850629899343556
Epoch: 52, training loss: 0.17649141020887618
Epoch: 53, training loss: 0.18010591235398563
Epoch: 54, training loss: 0.17438767408955796
Epoch: 55, training loss: 0.17199122191390218
Epoch: 56, training loss: 0.1719161678067555
Epoch: 57, training loss: 0.1666289601953698
Epoch: 58, training loss: 0.17182441515646618
Epoch: 59, training loss: 0.167482163004923
Epoch: 60, training loss: 0.17572372612621417
Epoch: 61, training loss: 0.1677026214438962
Epoch: 62, training loss: 0.16630703583288142
Epoch: 63, training loss: 0.16069039743145513
Epoch: 64, training loss: 0.16722930901124242
Epoch: 65, training loss: 0.15523113783090642
Epoch: 66, training loss: 0.15580762661753977
Epoch: 67, training loss: 0.15816274959926976
Epoch: 68, training loss: 0.16343570055144344
Epoch: 69, training loss: 0.16234760645780677
Epoch: 70, training loss: 0.1581360808375462
Epoch: 71, training loss: 0.15377924449726607
Epoch: 72, training loss: 0.15092991304694034
Epoch: 73, training loss: 0.1490853298415394
Epoch: 74, training loss: 0.15273836753141176
Epoch: 75, training loss: 0.14717654462916505
Epoch: 76, training loss: 0.1510472396539675
Epoch: 77, training loss: 0.147215982649954
Epoch: 78, training loss: 0.1469859353487797
Epoch: 79, training loss: 0.1552165364012617
Epoch: 80, training loss: 0.1434449178053618
Epoch: 81, training loss: 0.14858333367407173
Epoch: 82, training loss: 0.14478533814305483
Epoch: 83, training loss: 0.14446240416464945
Epoch: 84, training loss: 0.14087633531906774
Epoch: 85, training loss: 0.144205340111687
Epoch: 86, training loss: 0.1481096896992944
Epoch: 87, training loss: 0.14312265171876223
Epoch: 88, training loss: 0.14277339742419679
Epoch: 89, training loss: 0.1378463375019968
Epoch: 90, training loss: 0.14136548206610663
Epoch: 91, training loss: 0.1389700173905038
Epoch: 92, training loss: 0.13475713794128877
Epoch: 93, training loss: 0.13674607843943662
Epoch: 94, training loss: 0.13111063868983092
Epoch: 95, training loss: 0.13285092973958923
Epoch: 96, training loss: 0.128406714088727
Epoch: 97, training loss: 0.13355425311292188
Epoch: 98, training loss: 0.12993845854140357
Epoch: 99, training loss: 0.13166067942081686
