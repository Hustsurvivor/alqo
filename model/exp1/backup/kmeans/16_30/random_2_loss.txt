train LeroModelPairWise
Epoch: 0, training loss: 0.6335183571266149
Epoch: 1, training loss: 0.5691296720065996
Epoch: 2, training loss: 0.5264019489558128
Epoch: 3, training loss: 0.49329201527516897
Epoch: 4, training loss: 0.4678860957185099
Epoch: 5, training loss: 0.4520986923883067
Epoch: 6, training loss: 0.43284969464224715
Epoch: 7, training loss: 0.4189380756647338
Epoch: 8, training loss: 0.4053691153492431
Epoch: 9, training loss: 0.39052009015525385
Epoch: 10, training loss: 0.3761027264822606
Epoch: 11, training loss: 0.3683733146657183
Epoch: 12, training loss: 0.3566872421314262
Epoch: 13, training loss: 0.35288863618584976
Epoch: 14, training loss: 0.3333785789279713
Epoch: 15, training loss: 0.3346618650402425
Epoch: 16, training loss: 0.32254408817806096
Epoch: 17, training loss: 0.3107344179738775
Epoch: 18, training loss: 0.3022927507823227
Epoch: 19, training loss: 0.2933071881136241
Epoch: 20, training loss: 0.29553902039308705
Epoch: 21, training loss: 0.2816749998828546
Epoch: 22, training loss: 0.2771379168489626
Epoch: 23, training loss: 0.27237766565180704
Epoch: 24, training loss: 0.2651995132159181
Epoch: 25, training loss: 0.25345813671165235
Epoch: 26, training loss: 0.2580951384183342
Epoch: 27, training loss: 0.25081228996916466
Epoch: 28, training loss: 0.24374574298620433
Epoch: 29, training loss: 0.23609594047701338
Epoch: 30, training loss: 0.2341117319885647
Epoch: 31, training loss: 0.23044321062457618
Epoch: 32, training loss: 0.23230870090843683
Epoch: 33, training loss: 0.22973027524212
Epoch: 34, training loss: 0.2275910152811842
Epoch: 35, training loss: 0.2119812269668615
Epoch: 36, training loss: 0.2203320734504533
Epoch: 37, training loss: 0.21243173414550598
Epoch: 38, training loss: 0.20864118397592685
Epoch: 39, training loss: 0.21535987333153522
Epoch: 40, training loss: 0.20810510242707095
Epoch: 41, training loss: 0.2058268555365539
Epoch: 42, training loss: 0.202725331403644
Epoch: 43, training loss: 0.1926860970248775
Epoch: 44, training loss: 0.19959015999129445
Epoch: 45, training loss: 0.19859857905980421
Epoch: 46, training loss: 0.19274074126962773
Epoch: 47, training loss: 0.19040024927640942
Epoch: 48, training loss: 0.1900269712522887
Epoch: 49, training loss: 0.18444415315689666
Epoch: 50, training loss: 0.18662990503015917
Epoch: 51, training loss: 0.18436883674326
Epoch: 52, training loss: 0.17811608634338108
Epoch: 53, training loss: 0.17397771483908953
Epoch: 54, training loss: 0.18556594127908957
Epoch: 55, training loss: 0.17433474055178177
Epoch: 56, training loss: 0.17476679059317782
Epoch: 57, training loss: 0.17464056368458378
Epoch: 58, training loss: 0.17535720256061696
Epoch: 59, training loss: 0.17377044546230283
Epoch: 60, training loss: 0.17074781147733606
Epoch: 61, training loss: 0.1712215513720728
Epoch: 62, training loss: 0.16969530048664133
Epoch: 63, training loss: 0.16724208678346011
Epoch: 64, training loss: 0.16439889275804456
Epoch: 65, training loss: 0.16384718616707875
Epoch: 66, training loss: 0.16634376447992838
Epoch: 67, training loss: 0.15743177235194972
Epoch: 68, training loss: 0.16431736627063484
Epoch: 69, training loss: 0.16219860311864084
Epoch: 70, training loss: 0.15696052160919632
Epoch: 71, training loss: 0.16318041340796827
Epoch: 72, training loss: 0.15623179204313103
Epoch: 73, training loss: 0.15781465073836376
Epoch: 74, training loss: 0.15691334054372374
Epoch: 75, training loss: 0.1537913729034193
Epoch: 76, training loss: 0.15469598470172483
Epoch: 77, training loss: 0.15022036057876428
Epoch: 78, training loss: 0.15502613443283056
Epoch: 79, training loss: 0.1495158817663802
Epoch: 80, training loss: 0.14707465652971005
Epoch: 81, training loss: 0.14644871407406929
Epoch: 82, training loss: 0.15035753937355614
Epoch: 83, training loss: 0.1455200993924157
Epoch: 84, training loss: 0.1552695465628059
Epoch: 85, training loss: 0.14731149618282477
Epoch: 86, training loss: 0.14354657749755892
Epoch: 87, training loss: 0.145599341598714
Epoch: 88, training loss: 0.1422760028362827
Epoch: 89, training loss: 0.1391470777992823
Epoch: 90, training loss: 0.14517991366037752
Epoch: 91, training loss: 0.14729371059799365
Epoch: 92, training loss: 0.13916897103973408
Epoch: 93, training loss: 0.13987935629424716
Epoch: 94, training loss: 0.14028894398256125
Epoch: 95, training loss: 0.1432693723496862
Epoch: 96, training loss: 0.13761593966844246
Epoch: 97, training loss: 0.13725356307435527
Epoch: 98, training loss: 0.1396659877427996
Epoch: 99, training loss: 0.13348909277387128
