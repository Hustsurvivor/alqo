train LeroModelPairWise
Epoch: 0, training loss: 0.6096131869175004
Epoch: 1, training loss: 0.5470723949233208
Epoch: 2, training loss: 0.5132700251265315
Epoch: 3, training loss: 0.48771905067600685
Epoch: 4, training loss: 0.4653185095762165
Epoch: 5, training loss: 0.4479454378611505
Epoch: 6, training loss: 0.43561765934316493
Epoch: 7, training loss: 0.42103855148017943
Epoch: 8, training loss: 0.40331152421635924
Epoch: 9, training loss: 0.3890900719320805
Epoch: 10, training loss: 0.3823683661861906
Epoch: 11, training loss: 0.36711308624838107
Epoch: 12, training loss: 0.35642216757341905
Epoch: 13, training loss: 0.34611910457475825
Epoch: 14, training loss: 0.3381642185314403
Epoch: 15, training loss: 0.3299171092059603
Epoch: 16, training loss: 0.32117097270623607
Epoch: 17, training loss: 0.3168259162321142
Epoch: 18, training loss: 0.30274426676378857
Epoch: 19, training loss: 0.2926221545232889
Epoch: 20, training loss: 0.2916813925310981
Epoch: 21, training loss: 0.282258846647245
Epoch: 22, training loss: 0.2807054924421643
Epoch: 23, training loss: 0.27176270873479974
Epoch: 24, training loss: 0.26172626842197283
Epoch: 25, training loss: 0.26041485289925365
Epoch: 26, training loss: 0.25501051705017336
Epoch: 27, training loss: 0.2532866395716826
Epoch: 28, training loss: 0.24957053369546384
Epoch: 29, training loss: 0.24328035603768278
Epoch: 30, training loss: 0.23994042418350794
Epoch: 31, training loss: 0.23514348033520277
Epoch: 32, training loss: 0.23433346759438142
Epoch: 33, training loss: 0.22680100441098322
Epoch: 34, training loss: 0.23068938486845156
Epoch: 35, training loss: 0.21904941950544907
Epoch: 36, training loss: 0.2212688986224215
Epoch: 37, training loss: 0.21492981023773453
Epoch: 38, training loss: 0.21141248054141287
Epoch: 39, training loss: 0.2079903084440238
Epoch: 40, training loss: 0.203911846959693
Epoch: 41, training loss: 0.2013598036518549
Epoch: 42, training loss: 0.20541669285730396
Epoch: 43, training loss: 0.19433070934164798
Epoch: 44, training loss: 0.2022411053842626
Epoch: 45, training loss: 0.193031174917015
Epoch: 46, training loss: 0.1976765023936398
Epoch: 47, training loss: 0.18718820693353905
Epoch: 48, training loss: 0.19058507688164036
Epoch: 49, training loss: 0.19367164841800852
Epoch: 50, training loss: 0.18427000149526587
Epoch: 51, training loss: 0.18008288166495282
Epoch: 52, training loss: 0.18187209325836537
Epoch: 53, training loss: 0.18081863301664308
Epoch: 54, training loss: 0.17728302083446779
Epoch: 55, training loss: 0.18567369523679725
Epoch: 56, training loss: 0.17934441211689023
Epoch: 57, training loss: 0.17818985182708744
Epoch: 58, training loss: 0.17966350853745935
Epoch: 59, training loss: 0.17422154823605016
Epoch: 60, training loss: 0.17041814759481852
Epoch: 61, training loss: 0.17101958250374238
Epoch: 62, training loss: 0.16859900088166746
Epoch: 63, training loss: 0.1715867972161823
Epoch: 64, training loss: 0.17435868355933842
Epoch: 65, training loss: 0.16564571881730422
Epoch: 66, training loss: 0.16184067356344933
Epoch: 67, training loss: 0.16640055816238894
Epoch: 68, training loss: 0.1638756416268375
Epoch: 69, training loss: 0.16312809412822513
Epoch: 70, training loss: 0.1583244364190562
Epoch: 71, training loss: 0.169315459621433
Epoch: 72, training loss: 0.15917992495725053
Epoch: 73, training loss: 0.15829135828277593
Epoch: 74, training loss: 0.15507775559199866
Epoch: 75, training loss: 0.1531703435527389
Epoch: 76, training loss: 0.1585497277974877
Epoch: 77, training loss: 0.15243081920906254
Epoch: 78, training loss: 0.16038545005775892
Epoch: 79, training loss: 0.14966846375552992
Epoch: 80, training loss: 0.15195020731461178
Epoch: 81, training loss: 0.15237991947140692
Epoch: 82, training loss: 0.1478643574256129
Epoch: 83, training loss: 0.14323105412306
Epoch: 84, training loss: 0.1437145456823576
Epoch: 85, training loss: 0.14959842631173523
Epoch: 86, training loss: 0.14910347508133348
Epoch: 87, training loss: 0.1448756599033736
Epoch: 88, training loss: 0.13990433413312658
Epoch: 89, training loss: 0.14152099597013648
Epoch: 90, training loss: 0.1500640348006744
Epoch: 91, training loss: 0.14124955324102328
Epoch: 92, training loss: 0.13465283562607183
Epoch: 93, training loss: 0.13714069535590193
Epoch: 94, training loss: 0.14331420934307107
Epoch: 95, training loss: 0.13660685831978012
Epoch: 96, training loss: 0.13716948229165463
Epoch: 97, training loss: 0.14427523014393503
Epoch: 98, training loss: 0.13275471713789025
Epoch: 99, training loss: 0.13612179050093015
