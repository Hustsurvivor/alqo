train LeroModelPairWise
Epoch: 0, training loss: 0.6629602711250311
Epoch: 1, training loss: 0.6318111937110361
Epoch: 2, training loss: 0.6128421308084887
Epoch: 3, training loss: 0.5717431716028303
Epoch: 4, training loss: 0.5539503297829577
Epoch: 5, training loss: 0.5344076972880589
Epoch: 6, training loss: 0.4978981576668932
Epoch: 7, training loss: 0.4824543607666958
Epoch: 8, training loss: 0.4648130141217927
Epoch: 9, training loss: 0.45180835927832147
Epoch: 10, training loss: 0.41477396652365195
Epoch: 11, training loss: 0.41320995346847567
Epoch: 12, training loss: 0.3824776075999271
Epoch: 13, training loss: 0.3794670539308547
Epoch: 14, training loss: 0.37799243946182287
Epoch: 15, training loss: 0.3570692962513137
Epoch: 16, training loss: 0.33888185740236837
Epoch: 17, training loss: 0.319565036457612
Epoch: 18, training loss: 0.31467476961256574
Epoch: 19, training loss: 0.30594178244941994
Epoch: 20, training loss: 0.2925014328037819
Epoch: 21, training loss: 0.2658119397020457
Epoch: 22, training loss: 0.2550608254524405
Epoch: 23, training loss: 0.2750452020542687
Epoch: 24, training loss: 0.24736231399584693
Epoch: 25, training loss: 0.2234026233437234
Epoch: 26, training loss: 0.2165032876187514
Epoch: 27, training loss: 0.2134513819207485
Epoch: 28, training loss: 0.19690727500930216
Epoch: 29, training loss: 0.19927302436917343
Epoch: 30, training loss: 0.192560385247217
Epoch: 31, training loss: 0.19214520973262375
Epoch: 32, training loss: 0.167047992420941
Epoch: 33, training loss: 0.16631577103876682
Epoch: 34, training loss: 0.17591659872986065
Epoch: 35, training loss: 0.14484971576707983
Epoch: 36, training loss: 0.1494062925716882
Epoch: 37, training loss: 0.16036023634774005
Epoch: 38, training loss: 0.16406919154486552
Epoch: 39, training loss: 0.14622147468903463
Epoch: 40, training loss: 0.1371583850883526
Epoch: 41, training loss: 0.13288247827744734
Epoch: 42, training loss: 0.1309672147586315
Epoch: 43, training loss: 0.1291698437279268
Epoch: 44, training loss: 0.12712074276483368
Epoch: 45, training loss: 0.11117631596606359
Epoch: 46, training loss: 0.11750369952683805
Epoch: 47, training loss: 0.11106453754512949
Epoch: 48, training loss: 0.11217553913868264
Epoch: 49, training loss: 0.11730539257528784
Epoch: 50, training loss: 0.11887133701590491
Epoch: 51, training loss: 0.11039073493581103
Epoch: 52, training loss: 0.10444613331097535
Epoch: 53, training loss: 0.09588114535376738
Epoch: 54, training loss: 0.10800750874904282
Epoch: 55, training loss: 0.09524820707549825
Epoch: 56, training loss: 0.1040705027624433
Epoch: 57, training loss: 0.09641582129886135
Epoch: 58, training loss: 0.10486095738536845
Epoch: 59, training loss: 0.09914292096699281
Epoch: 60, training loss: 0.09035580173832132
Epoch: 61, training loss: 0.0929344961374134
Epoch: 62, training loss: 0.09205448815197945
Epoch: 63, training loss: 0.09212309832876771
Epoch: 64, training loss: 0.08527868208365046
Epoch: 65, training loss: 0.09098186019852021
Epoch: 66, training loss: 0.092992175427032
Epoch: 67, training loss: 0.08140122571434029
Epoch: 68, training loss: 0.08459315389377255
Epoch: 69, training loss: 0.09309702280279092
Epoch: 70, training loss: 0.08150729307389021
Epoch: 71, training loss: 0.08325277212607954
Epoch: 72, training loss: 0.07930520976839567
Epoch: 73, training loss: 0.07330782843648831
Epoch: 74, training loss: 0.0684719408239501
Epoch: 75, training loss: 0.0809026961074308
Epoch: 76, training loss: 0.07620815764725539
Epoch: 77, training loss: 0.08052879672413894
Epoch: 78, training loss: 0.0748140579946044
Epoch: 79, training loss: 0.07472526217666499
Epoch: 80, training loss: 0.06312117820967945
Epoch: 81, training loss: 0.0698618701407849
Epoch: 82, training loss: 0.07332398825109568
Epoch: 83, training loss: 0.0659186418970459
Epoch: 84, training loss: 0.07068242240877008
Epoch: 85, training loss: 0.07164212406971565
Epoch: 86, training loss: 0.06588107814753463
Epoch: 87, training loss: 0.07522159934001013
Epoch: 88, training loss: 0.0685803132757494
Epoch: 89, training loss: 0.0639114893946838
Epoch: 90, training loss: 0.0665785943191331
Epoch: 91, training loss: 0.07437355110472152
Epoch: 92, training loss: 0.0628513980505751
Epoch: 93, training loss: 0.06038100073577559
Epoch: 94, training loss: 0.07060782298559523
Epoch: 95, training loss: 0.0630327129830176
Epoch: 96, training loss: 0.07103607330425377
Epoch: 97, training loss: 0.06563456676200315
Epoch: 98, training loss: 0.05924181780810686
Epoch: 99, training loss: 0.07249731840688155
