train LeroModelPairWise
Epoch: 0, training loss: 0.6580683895868356
Epoch: 1, training loss: 0.6402743189137025
Epoch: 2, training loss: 0.6102222851565612
Epoch: 3, training loss: 0.5803442587244935
Epoch: 4, training loss: 0.5624205529604835
Epoch: 5, training loss: 0.5475520444436587
Epoch: 6, training loss: 0.5165592497800529
Epoch: 7, training loss: 0.5083527300605271
Epoch: 8, training loss: 0.4859065372135393
Epoch: 9, training loss: 0.48140725554001096
Epoch: 10, training loss: 0.45091213913584605
Epoch: 11, training loss: 0.43180994856816113
Epoch: 12, training loss: 0.43760683390843996
Epoch: 13, training loss: 0.4196144210668333
Epoch: 14, training loss: 0.40358428516999617
Epoch: 15, training loss: 0.36653031766132904
Epoch: 16, training loss: 0.37589185836066763
Epoch: 17, training loss: 0.356443006539912
Epoch: 18, training loss: 0.3500295111357296
Epoch: 19, training loss: 0.324696986814212
Epoch: 20, training loss: 0.3202403299186951
Epoch: 21, training loss: 0.3292807803728788
Epoch: 22, training loss: 0.30456781250616616
Epoch: 23, training loss: 0.2809228303755702
Epoch: 24, training loss: 0.2772697195003787
Epoch: 25, training loss: 0.27957660729757633
Epoch: 26, training loss: 0.270266974843255
Epoch: 27, training loss: 0.2702154671906187
Epoch: 28, training loss: 0.25036896683119275
Epoch: 29, training loss: 0.2527663238509143
Epoch: 30, training loss: 0.22779415056926047
Epoch: 31, training loss: 0.22087550295161484
Epoch: 32, training loss: 0.2103515494853908
Epoch: 33, training loss: 0.19760876295689017
Epoch: 34, training loss: 0.20935744714014537
Epoch: 35, training loss: 0.19309812013840616
Epoch: 36, training loss: 0.18537371603763403
Epoch: 37, training loss: 0.18857620718917503
Epoch: 38, training loss: 0.18734641120683432
Epoch: 39, training loss: 0.16229212177736824
Epoch: 40, training loss: 0.16202642055248392
Epoch: 41, training loss: 0.13204754793925053
Epoch: 42, training loss: 0.14540754984879953
Epoch: 43, training loss: 0.14367409659990155
Epoch: 44, training loss: 0.1401656132787448
Epoch: 45, training loss: 0.13450172565405216
Epoch: 46, training loss: 0.15329791469107182
Epoch: 47, training loss: 0.1382435782435356
Epoch: 48, training loss: 0.10967904421366378
Epoch: 49, training loss: 0.12777764034132189
Epoch: 50, training loss: 0.12380466890403491
Epoch: 51, training loss: 0.11846354239869257
Epoch: 52, training loss: 0.11533126712494593
Epoch: 53, training loss: 0.1191485694479157
Epoch: 54, training loss: 0.11885912238691879
Epoch: 55, training loss: 0.10536663575886969
Epoch: 56, training loss: 0.11655753983156687
Epoch: 57, training loss: 0.10577810535920669
Epoch: 58, training loss: 0.10078265563647233
Epoch: 59, training loss: 0.10862254897306613
Epoch: 60, training loss: 0.10868676455563779
Epoch: 61, training loss: 0.10265878889555484
Epoch: 62, training loss: 0.09306979726143107
Epoch: 63, training loss: 0.10043765841323785
Epoch: 64, training loss: 0.09121622600963883
Epoch: 65, training loss: 0.10235361389058037
Epoch: 66, training loss: 0.09464369039874906
Epoch: 67, training loss: 0.07414240110317637
Epoch: 68, training loss: 0.10170340770575237
Epoch: 69, training loss: 0.0935847643617409
Epoch: 70, training loss: 0.09182104228146093
Epoch: 71, training loss: 0.08671657197963477
Epoch: 72, training loss: 0.09455709759472128
Epoch: 73, training loss: 0.0916875567828863
Epoch: 74, training loss: 0.08453578892786036
Epoch: 75, training loss: 0.08081949292833626
Epoch: 76, training loss: 0.08852108875948969
Epoch: 77, training loss: 0.07575430686565233
Epoch: 78, training loss: 0.08614096278227086
Epoch: 79, training loss: 0.07923049408210199
Epoch: 80, training loss: 0.09535505830832988
Epoch: 81, training loss: 0.09049582400968248
Epoch: 82, training loss: 0.08241155374992351
Epoch: 83, training loss: 0.08030749335275635
Epoch: 84, training loss: 0.08268709913867779
Epoch: 85, training loss: 0.0779733284770445
Epoch: 86, training loss: 0.07354638839913187
Epoch: 87, training loss: 0.07509458111559822
Epoch: 88, training loss: 0.08490954065636959
Epoch: 89, training loss: 0.07182527949752976
Epoch: 90, training loss: 0.07542794604013023
Epoch: 91, training loss: 0.08216694463371475
Epoch: 92, training loss: 0.07901282263609669
Epoch: 93, training loss: 0.08152226910183401
Epoch: 94, training loss: 0.07044400369605026
Epoch: 95, training loss: 0.0714356246143587
Epoch: 96, training loss: 0.07339743088854331
Epoch: 97, training loss: 0.07836986545922338
Epoch: 98, training loss: 0.0678022325057971
Epoch: 99, training loss: 0.06618126580249832
