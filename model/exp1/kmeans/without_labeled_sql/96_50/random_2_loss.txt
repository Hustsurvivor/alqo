train LeroModelPairWise
Epoch: 0, training loss: 0.6424910849985241
Epoch: 1, training loss: 0.5954226310669212
Epoch: 2, training loss: 0.5753122351547004
Epoch: 3, training loss: 0.5510304205795358
Epoch: 4, training loss: 0.5158267013298591
Epoch: 5, training loss: 0.5012620958296264
Epoch: 6, training loss: 0.5091145937768904
Epoch: 7, training loss: 0.46858181415648226
Epoch: 8, training loss: 0.44585255686287395
Epoch: 9, training loss: 0.42415178034582185
Epoch: 10, training loss: 0.4150474423950146
Epoch: 11, training loss: 0.38439653943419494
Epoch: 12, training loss: 0.3808124661851454
Epoch: 13, training loss: 0.35817573523647184
Epoch: 14, training loss: 0.3633299610465
Epoch: 15, training loss: 0.33679500658653566
Epoch: 16, training loss: 0.3247599223278903
Epoch: 17, training loss: 0.28769641625848247
Epoch: 18, training loss: 0.28183209195389236
Epoch: 19, training loss: 0.2607887102282806
Epoch: 20, training loss: 0.2618340421711358
Epoch: 21, training loss: 0.25756013557874136
Epoch: 22, training loss: 0.23853877247240987
Epoch: 23, training loss: 0.22079476759400996
Epoch: 24, training loss: 0.20331883396842865
Epoch: 25, training loss: 0.18511725558936185
Epoch: 26, training loss: 0.17813446738799435
Epoch: 27, training loss: 0.18668926514740772
Epoch: 28, training loss: 0.16556783922391138
Epoch: 29, training loss: 0.17011974533727844
Epoch: 30, training loss: 0.1539563194188868
Epoch: 31, training loss: 0.14870566952753594
Epoch: 32, training loss: 0.13518629624498807
Epoch: 33, training loss: 0.13691264172660653
Epoch: 34, training loss: 0.16352559105174508
Epoch: 35, training loss: 0.1413736085094684
Epoch: 36, training loss: 0.15232237693362566
Epoch: 37, training loss: 0.12089115800290232
Epoch: 38, training loss: 0.1396618470973252
Epoch: 39, training loss: 0.11618135845589063
Epoch: 40, training loss: 0.12227471735784423
Epoch: 41, training loss: 0.11352715749877777
Epoch: 42, training loss: 0.10299595224564058
Epoch: 43, training loss: 0.09931552048125651
Epoch: 44, training loss: 0.10008915964752818
Epoch: 45, training loss: 0.09321740589623867
Epoch: 46, training loss: 0.10654320973042486
Epoch: 47, training loss: 0.10420705836903194
Epoch: 48, training loss: 0.09599290280743182
Epoch: 49, training loss: 0.08614367527448405
Epoch: 50, training loss: 0.07977405597081709
Epoch: 51, training loss: 0.09598873560410821
Epoch: 52, training loss: 0.09451121360095449
Epoch: 53, training loss: 0.07627606601263849
Epoch: 54, training loss: 0.08047732846134621
Epoch: 55, training loss: 0.08503614168957113
Epoch: 56, training loss: 0.08172318052381752
Epoch: 57, training loss: 0.07954908072802465
Epoch: 58, training loss: 0.08194003883986081
Epoch: 59, training loss: 0.08590365162466354
Epoch: 60, training loss: 0.07760822613249316
Epoch: 61, training loss: 0.08589305539222603
Epoch: 62, training loss: 0.08265008699069182
Epoch: 63, training loss: 0.08054610331303913
Epoch: 64, training loss: 0.07581896052310824
Epoch: 65, training loss: 0.07325351735934409
Epoch: 66, training loss: 0.07566794533799232
Epoch: 67, training loss: 0.07121837230657124
Epoch: 68, training loss: 0.06575759202532877
Epoch: 69, training loss: 0.06302970101620521
Epoch: 70, training loss: 0.07246451484648384
Epoch: 71, training loss: 0.07302419998097595
Epoch: 72, training loss: 0.07114843296537701
Epoch: 73, training loss: 0.060332643298345145
Epoch: 74, training loss: 0.06538424150700604
Epoch: 75, training loss: 0.06717486968782405
Epoch: 76, training loss: 0.07002719560084128
Epoch: 77, training loss: 0.06385400511113044
Epoch: 78, training loss: 0.06491848876172744
Epoch: 79, training loss: 0.07539754094568986
Epoch: 80, training loss: 0.06601978740272547
Epoch: 81, training loss: 0.06828220759664712
Epoch: 82, training loss: 0.07305658639353492
Epoch: 83, training loss: 0.06858971412683693
Epoch: 84, training loss: 0.06003677722720547
Epoch: 85, training loss: 0.05881830219250521
Epoch: 86, training loss: 0.058456339103829295
Epoch: 87, training loss: 0.06417942654117406
Epoch: 88, training loss: 0.06631253276693806
Epoch: 89, training loss: 0.06272565409127663
Epoch: 90, training loss: 0.0626661154227291
Epoch: 91, training loss: 0.049898970110303614
Epoch: 92, training loss: 0.05306500032412773
Epoch: 93, training loss: 0.06275255536236866
Epoch: 94, training loss: 0.06540302794599667
Epoch: 95, training loss: 0.06205932365219341
Epoch: 96, training loss: 0.0571834987099715
Epoch: 97, training loss: 0.06404575258632139
Epoch: 98, training loss: 0.06404977814089823
Epoch: 99, training loss: 0.054745583983736176
