train LeroModelPairWise
Epoch: 0, training loss: 0.6064240417165492
Epoch: 1, training loss: 0.5386979039717265
Epoch: 2, training loss: 0.508443684925709
Epoch: 3, training loss: 0.48571594070008356
Epoch: 4, training loss: 0.4728506184663405
Epoch: 5, training loss: 0.45538869765613016
Epoch: 6, training loss: 0.44528387858503576
Epoch: 7, training loss: 0.4388216428911862
Epoch: 8, training loss: 0.4294238177488909
Epoch: 9, training loss: 0.4195980862952735
Epoch: 10, training loss: 0.4128345260594694
Epoch: 11, training loss: 0.404195659342561
Epoch: 12, training loss: 0.39620229425447245
Epoch: 13, training loss: 0.3908560061967601
Epoch: 14, training loss: 0.38119846466309093
Epoch: 15, training loss: 0.3755367955896229
Epoch: 16, training loss: 0.3676480263332668
Epoch: 17, training loss: 0.36614057340324807
Epoch: 18, training loss: 0.35592767161813543
Epoch: 19, training loss: 0.35394642459265996
Epoch: 20, training loss: 0.3440834672617512
Epoch: 21, training loss: 0.3407852726971167
Epoch: 22, training loss: 0.33620164359149457
Epoch: 23, training loss: 0.33205181878160417
Epoch: 24, training loss: 0.324893943750611
Epoch: 25, training loss: 0.32235827482886514
Epoch: 26, training loss: 0.31377407713108313
Epoch: 27, training loss: 0.3105259911713751
Epoch: 28, training loss: 0.30358301899496715
Epoch: 29, training loss: 0.3054900633996682
Epoch: 30, training loss: 0.3004873389013852
Epoch: 31, training loss: 0.29436241031637195
Epoch: 32, training loss: 0.2955199873236341
Epoch: 33, training loss: 0.2874406671850522
Epoch: 34, training loss: 0.28676826486470836
Epoch: 35, training loss: 0.28195630826098955
Epoch: 36, training loss: 0.28207086096193607
Epoch: 37, training loss: 0.2749737921336138
Epoch: 38, training loss: 0.2706433066334408
Epoch: 39, training loss: 0.2713600339854309
Epoch: 40, training loss: 0.26644011543844487
Epoch: 41, training loss: 0.26480218558574586
Epoch: 42, training loss: 0.26243778430296816
Epoch: 43, training loss: 0.2599195006707053
Epoch: 44, training loss: 0.25775807525153777
Epoch: 45, training loss: 0.2550018255352332
Epoch: 46, training loss: 0.25138951276494054
Epoch: 47, training loss: 0.24986652294574663
Epoch: 48, training loss: 0.24763696490706108
Epoch: 49, training loss: 0.2434762528379198
Epoch: 50, training loss: 0.24160706714935018
Epoch: 51, training loss: 0.2401825070518173
Epoch: 52, training loss: 0.23563794189934248
Epoch: 53, training loss: 0.24191839929810952
Epoch: 54, training loss: 0.23243008151153619
Epoch: 55, training loss: 0.23392693161560432
Epoch: 56, training loss: 0.23410765416227333
Epoch: 57, training loss: 0.22756766802369022
Epoch: 58, training loss: 0.22886825702171926
Epoch: 59, training loss: 0.22554742541550837
Epoch: 60, training loss: 0.22509924606137555
Epoch: 61, training loss: 0.22160302092271922
Epoch: 62, training loss: 0.222498512608449
Epoch: 63, training loss: 0.21751607793814737
Epoch: 64, training loss: 0.21745097039907238
Epoch: 65, training loss: 0.21930758564707095
Epoch: 66, training loss: 0.21572298113952454
Epoch: 67, training loss: 0.2100834814563629
Epoch: 68, training loss: 0.2150348909876664
Epoch: 69, training loss: 0.2137543334692684
Epoch: 70, training loss: 0.21320724572391658
Epoch: 71, training loss: 0.2102592204472109
Epoch: 72, training loss: 0.20612594336808499
Epoch: 73, training loss: 0.2047215546500694
Epoch: 74, training loss: 0.20587603139825636
Epoch: 75, training loss: 0.20255673088219142
Epoch: 76, training loss: 0.20211348899907386
Epoch: 77, training loss: 0.20077408549236314
Epoch: 78, training loss: 0.198889134819387
Epoch: 79, training loss: 0.20408663030154808
Epoch: 80, training loss: 0.19598755172034255
Epoch: 81, training loss: 0.1973184183241675
Epoch: 82, training loss: 0.1953821171329491
Epoch: 83, training loss: 0.19425952443390393
Epoch: 84, training loss: 0.195971587560086
Epoch: 85, training loss: 0.19152952263079925
Epoch: 86, training loss: 0.19395197685004495
Epoch: 87, training loss: 0.19289757226226073
Epoch: 88, training loss: 0.187745520927219
Epoch: 89, training loss: 0.19142957917234732
Epoch: 90, training loss: 0.1906295297632589
Epoch: 91, training loss: 0.18648742416512548
Epoch: 92, training loss: 0.18938166490932404
Epoch: 93, training loss: 0.18607704655745325
Epoch: 94, training loss: 0.1808843016163649
Epoch: 95, training loss: 0.1825861830740614
Epoch: 96, training loss: 0.1839109104795306
Epoch: 97, training loss: 0.1803338640766044
Epoch: 98, training loss: 0.1831765382484828
Epoch: 99, training loss: 0.1780071758108612
