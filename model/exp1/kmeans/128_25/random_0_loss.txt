train LeroModelPairWise
Epoch: 0, training loss: 0.6041536996558684
Epoch: 1, training loss: 0.5420256186709221
Epoch: 2, training loss: 0.5112456899999689
Epoch: 3, training loss: 0.49017295818095385
Epoch: 4, training loss: 0.47727393032986376
Epoch: 5, training loss: 0.461014070246039
Epoch: 6, training loss: 0.450845001082663
Epoch: 7, training loss: 0.44070128626191263
Epoch: 8, training loss: 0.4294105342403913
Epoch: 9, training loss: 0.421293487365235
Epoch: 10, training loss: 0.4177508314297241
Epoch: 11, training loss: 0.4119645132756359
Epoch: 12, training loss: 0.39634978131381415
Epoch: 13, training loss: 0.392647287985273
Epoch: 14, training loss: 0.38152024266349266
Epoch: 15, training loss: 0.3765295655147824
Epoch: 16, training loss: 0.37123758779730837
Epoch: 17, training loss: 0.3660859597704558
Epoch: 18, training loss: 0.35712415922796675
Epoch: 19, training loss: 0.3516713980787643
Epoch: 20, training loss: 0.35090957497267594
Epoch: 21, training loss: 0.3402557622064469
Epoch: 22, training loss: 0.33582064894407543
Epoch: 23, training loss: 0.32855921289389045
Epoch: 24, training loss: 0.32695921769916153
Epoch: 25, training loss: 0.3232810386861145
Epoch: 26, training loss: 0.31556754095067935
Epoch: 27, training loss: 0.3065810164745056
Epoch: 28, training loss: 0.30853575680611134
Epoch: 29, training loss: 0.3005052750470653
Epoch: 30, training loss: 0.2978538515532043
Epoch: 31, training loss: 0.2980141533131826
Epoch: 32, training loss: 0.2888231804495007
Epoch: 33, training loss: 0.2895496337759008
Epoch: 34, training loss: 0.28537294860746837
Epoch: 35, training loss: 0.28480753965545413
Epoch: 36, training loss: 0.2779328187199367
Epoch: 37, training loss: 0.2729565398496231
Epoch: 38, training loss: 0.26685258289200686
Epoch: 39, training loss: 0.26833339289310204
Epoch: 40, training loss: 0.26671064478578477
Epoch: 41, training loss: 0.2634374245102473
Epoch: 42, training loss: 0.25950811447229116
Epoch: 43, training loss: 0.258603840332832
Epoch: 44, training loss: 0.25504758190541166
Epoch: 45, training loss: 0.24951691588174285
Epoch: 46, training loss: 0.2513675995753294
Epoch: 47, training loss: 0.2452348735034639
Epoch: 48, training loss: 0.24224124851431017
Epoch: 49, training loss: 0.2417374843928148
Epoch: 50, training loss: 0.24383713736313975
Epoch: 51, training loss: 0.24039237260157115
Epoch: 52, training loss: 0.23468938514535823
Epoch: 53, training loss: 0.2348384101134065
Epoch: 54, training loss: 0.23204371065210003
Epoch: 55, training loss: 0.22803269806857598
Epoch: 56, training loss: 0.22691518688238352
Epoch: 57, training loss: 0.22666468421031327
Epoch: 58, training loss: 0.22089437610042298
Epoch: 59, training loss: 0.21893269854969866
Epoch: 60, training loss: 0.21665988811421147
Epoch: 61, training loss: 0.21994578232360967
Epoch: 62, training loss: 0.21952923541199304
Epoch: 63, training loss: 0.21878199110699387
Epoch: 64, training loss: 0.21513182944353382
Epoch: 65, training loss: 0.21435201806906018
Epoch: 66, training loss: 0.20975892308028882
Epoch: 67, training loss: 0.20426394949381582
Epoch: 68, training loss: 0.20534115605094774
Epoch: 69, training loss: 0.20787482916482247
Epoch: 70, training loss: 0.20386954889403164
Epoch: 71, training loss: 0.20303944597206366
Epoch: 72, training loss: 0.2031604831438009
Epoch: 73, training loss: 0.20071994895801798
Epoch: 74, training loss: 0.19992860314849983
Epoch: 75, training loss: 0.19569079866608585
Epoch: 76, training loss: 0.20069724726230262
Epoch: 77, training loss: 0.1955688199013483
Epoch: 78, training loss: 0.1959488172352689
Epoch: 79, training loss: 0.195631982084924
Epoch: 80, training loss: 0.19386498759643303
Epoch: 81, training loss: 0.18938089763616026
Epoch: 82, training loss: 0.19169385431256517
Epoch: 83, training loss: 0.18936514299902257
Epoch: 84, training loss: 0.18989826529810178
Epoch: 85, training loss: 0.19002320114760024
Epoch: 86, training loss: 0.18843775164159815
Epoch: 87, training loss: 0.18169844051390746
Epoch: 88, training loss: 0.18714963263843012
Epoch: 89, training loss: 0.18097516023922328
Epoch: 90, training loss: 0.18576883233962882
Epoch: 91, training loss: 0.18621286755822747
Epoch: 92, training loss: 0.17964064327484347
Epoch: 93, training loss: 0.17632380552429164
Epoch: 94, training loss: 0.17256327262329393
Epoch: 95, training loss: 0.18031953397098346
Epoch: 96, training loss: 0.17990983985118095
Epoch: 97, training loss: 0.1733900010314952
Epoch: 98, training loss: 0.17821999589901405
Epoch: 99, training loss: 0.1711468407820488
