train LeroModelPairWise
Epoch: 0, training loss: 0.6039623028278274
Epoch: 1, training loss: 0.5357679635887782
Epoch: 2, training loss: 0.5039781024689983
Epoch: 3, training loss: 0.48314335880201026
Epoch: 4, training loss: 0.4661202845120703
Epoch: 5, training loss: 0.4523749897484924
Epoch: 6, training loss: 0.4443059300829456
Epoch: 7, training loss: 0.4346331412209471
Epoch: 8, training loss: 0.42333802618170235
Epoch: 9, training loss: 0.415567544994679
Epoch: 10, training loss: 0.4070673163181909
Epoch: 11, training loss: 0.39552610363402985
Epoch: 12, training loss: 0.39283057589521925
Epoch: 13, training loss: 0.3843301748774626
Epoch: 14, training loss: 0.3765181094205905
Epoch: 15, training loss: 0.3740392983473352
Epoch: 16, training loss: 0.36844394188020135
Epoch: 17, training loss: 0.3613617428827144
Epoch: 18, training loss: 0.357568602455405
Epoch: 19, training loss: 0.35016750384697526
Epoch: 20, training loss: 0.3399337666035862
Epoch: 21, training loss: 0.33802751510970486
Epoch: 22, training loss: 0.3310374695122351
Epoch: 23, training loss: 0.3234895990149372
Epoch: 24, training loss: 0.319229980080934
Epoch: 25, training loss: 0.31769644820978027
Epoch: 26, training loss: 0.3092804648984082
Epoch: 27, training loss: 0.3075301144594087
Epoch: 28, training loss: 0.29912767384649475
Epoch: 29, training loss: 0.2967574576193896
Epoch: 30, training loss: 0.2929518644032564
Epoch: 31, training loss: 0.28542107850771287
Epoch: 32, training loss: 0.28815023467510764
Epoch: 33, training loss: 0.27963518421112565
Epoch: 34, training loss: 0.27343617668941766
Epoch: 35, training loss: 0.27744654160067217
Epoch: 36, training loss: 0.26676147877716727
Epoch: 37, training loss: 0.2634430136579886
Epoch: 38, training loss: 0.26181768241224923
Epoch: 39, training loss: 0.25791331848591775
Epoch: 40, training loss: 0.2609433145177143
Epoch: 41, training loss: 0.2548467185148304
Epoch: 42, training loss: 0.25166518595690035
Epoch: 43, training loss: 0.24870348442973497
Epoch: 44, training loss: 0.24742412687727533
Epoch: 45, training loss: 0.24671902548227492
Epoch: 46, training loss: 0.2445084217119911
Epoch: 47, training loss: 0.23784822256190852
Epoch: 48, training loss: 0.23555259864076383
Epoch: 49, training loss: 0.23668465229405278
Epoch: 50, training loss: 0.23892647130711195
Epoch: 51, training loss: 0.23031143164990037
Epoch: 52, training loss: 0.22906669003168442
Epoch: 53, training loss: 0.2281192659941624
Epoch: 54, training loss: 0.2237631927683097
Epoch: 55, training loss: 0.22418848883172904
Epoch: 56, training loss: 0.22963008457222162
Epoch: 57, training loss: 0.21758804445197663
Epoch: 58, training loss: 0.22080023768318338
Epoch: 59, training loss: 0.21996541123295443
Epoch: 60, training loss: 0.21416410095651447
Epoch: 61, training loss: 0.2154434582999584
Epoch: 62, training loss: 0.21540191990481874
Epoch: 63, training loss: 0.21537932498085924
Epoch: 64, training loss: 0.2099851532796613
Epoch: 65, training loss: 0.2100839336294118
Epoch: 66, training loss: 0.2106840563965753
Epoch: 67, training loss: 0.20269302068257844
Epoch: 68, training loss: 0.20434979420577293
Epoch: 69, training loss: 0.20794065104500611
Epoch: 70, training loss: 0.2011789487852565
Epoch: 71, training loss: 0.20103773018347648
Epoch: 72, training loss: 0.1987255685732804
Epoch: 73, training loss: 0.19832353555839752
Epoch: 74, training loss: 0.19526375391774053
Epoch: 75, training loss: 0.19591841983717365
Epoch: 76, training loss: 0.195750923455827
Epoch: 77, training loss: 0.1968666987141272
Epoch: 78, training loss: 0.19204060818130725
Epoch: 79, training loss: 0.19123160797783967
Epoch: 80, training loss: 0.19369350823174084
Epoch: 81, training loss: 0.18921826552364412
Epoch: 82, training loss: 0.18956487302283223
Epoch: 83, training loss: 0.1852828089332647
Epoch: 84, training loss: 0.18609985314942515
Epoch: 85, training loss: 0.1846556073305085
Epoch: 86, training loss: 0.18503582094053964
Epoch: 87, training loss: 0.18720690644225646
Epoch: 88, training loss: 0.18281217247366896
Epoch: 89, training loss: 0.18456744630419342
Epoch: 90, training loss: 0.17959001622313
Epoch: 91, training loss: 0.1842388863723766
Epoch: 92, training loss: 0.17907062619033728
Epoch: 93, training loss: 0.1761637091445447
Epoch: 94, training loss: 0.1796936875701126
Epoch: 95, training loss: 0.17546731403222424
Epoch: 96, training loss: 0.17838294460327314
Epoch: 97, training loss: 0.17340352332260953
Epoch: 98, training loss: 0.17160642202126414
Epoch: 99, training loss: 0.17404738221950392
