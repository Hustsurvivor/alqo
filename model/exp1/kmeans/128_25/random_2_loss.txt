train LeroModelPairWise
Epoch: 0, training loss: 0.608747821883171
Epoch: 1, training loss: 0.5401551554162766
Epoch: 2, training loss: 0.5095580750258952
Epoch: 3, training loss: 0.48901329805667415
Epoch: 4, training loss: 0.4698418321697086
Epoch: 5, training loss: 0.45939264887476056
Epoch: 6, training loss: 0.44660168434356257
Epoch: 7, training loss: 0.4320768098096334
Epoch: 8, training loss: 0.42825808355794925
Epoch: 9, training loss: 0.414117145283025
Epoch: 10, training loss: 0.40921633883030817
Epoch: 11, training loss: 0.39968740318674106
Epoch: 12, training loss: 0.3926535771240255
Epoch: 13, training loss: 0.38740344488697565
Epoch: 14, training loss: 0.3770804752870347
Epoch: 15, training loss: 0.37027973681835014
Epoch: 16, training loss: 0.362559526031982
Epoch: 17, training loss: 0.3576238597789885
Epoch: 18, training loss: 0.34851581127011244
Epoch: 19, training loss: 0.3409943953238289
Epoch: 20, training loss: 0.3374712351989289
Epoch: 21, training loss: 0.3311872389866178
Epoch: 22, training loss: 0.32216332679527704
Epoch: 23, training loss: 0.3153539057857148
Epoch: 24, training loss: 0.31310363449687795
Epoch: 25, training loss: 0.3065575387507982
Epoch: 26, training loss: 0.3038882701440404
Epoch: 27, training loss: 0.2986869332993581
Epoch: 28, training loss: 0.2962789207638817
Epoch: 29, training loss: 0.2907173540036062
Epoch: 30, training loss: 0.2849017697615656
Epoch: 31, training loss: 0.279681801854991
Epoch: 32, training loss: 0.27588205184151254
Epoch: 33, training loss: 0.2717132784214837
Epoch: 34, training loss: 0.275220957963211
Epoch: 35, training loss: 0.26544603612821027
Epoch: 36, training loss: 0.26148268940857
Epoch: 37, training loss: 0.2594388241570597
Epoch: 38, training loss: 0.2583234650958927
Epoch: 39, training loss: 0.25281107392321306
Epoch: 40, training loss: 0.24841102103306428
Epoch: 41, training loss: 0.24671276963094613
Epoch: 42, training loss: 0.24317933599885497
Epoch: 43, training loss: 0.24342967546770303
Epoch: 44, training loss: 0.24237156376760358
Epoch: 45, training loss: 0.2359800570933057
Epoch: 46, training loss: 0.2355573640334691
Epoch: 47, training loss: 0.22757774652234167
Epoch: 48, training loss: 0.23192299216965725
Epoch: 49, training loss: 0.22830341778165952
Epoch: 50, training loss: 0.22920804730508984
Epoch: 51, training loss: 0.2256012340580072
Epoch: 52, training loss: 0.2239432212100506
Epoch: 53, training loss: 0.21750846473096186
Epoch: 54, training loss: 0.2182673792879613
Epoch: 55, training loss: 0.2190890358530728
Epoch: 56, training loss: 0.21393401659510852
Epoch: 57, training loss: 0.21800958790387998
Epoch: 58, training loss: 0.21066672143503593
Epoch: 59, training loss: 0.2089392312728882
Epoch: 60, training loss: 0.20587738207475037
Epoch: 61, training loss: 0.20546930398743735
Epoch: 62, training loss: 0.20461588141201084
Epoch: 63, training loss: 0.20055811300496923
Epoch: 64, training loss: 0.20154028278697497
Epoch: 65, training loss: 0.20015190974526634
Epoch: 66, training loss: 0.19881500915330777
Epoch: 67, training loss: 0.1966496105704866
Epoch: 68, training loss: 0.1951381132737694
Epoch: 69, training loss: 0.19366929111484454
Epoch: 70, training loss: 0.1946597448284083
Epoch: 71, training loss: 0.1909878984478917
Epoch: 72, training loss: 0.1904163820024101
Epoch: 73, training loss: 0.1931242952664888
Epoch: 74, training loss: 0.18953002980491862
Epoch: 75, training loss: 0.18728760960094645
Epoch: 76, training loss: 0.1870799686915136
Epoch: 77, training loss: 0.18213003163738004
Epoch: 78, training loss: 0.1814656365090492
Epoch: 79, training loss: 0.1821164451272708
Epoch: 80, training loss: 0.1830081170928789
Epoch: 81, training loss: 0.17897618677767377
Epoch: 82, training loss: 0.1780041339062933
Epoch: 83, training loss: 0.1794609733344103
Epoch: 84, training loss: 0.17456109607447132
Epoch: 85, training loss: 0.1742910677035021
Epoch: 86, training loss: 0.17349265971107702
Epoch: 87, training loss: 0.17354948757659683
Epoch: 88, training loss: 0.17272544512921134
Epoch: 89, training loss: 0.17204913695645085
Epoch: 90, training loss: 0.16906337699956792
Epoch: 91, training loss: 0.1682228234668572
Epoch: 92, training loss: 0.1734240435304653
Epoch: 93, training loss: 0.16641556584597572
Epoch: 94, training loss: 0.16748799350747853
Epoch: 95, training loss: 0.1681054399318854
Epoch: 96, training loss: 0.1682848809725488
Epoch: 97, training loss: 0.16592469606880603
Epoch: 98, training loss: 0.1658911427782132
Epoch: 99, training loss: 0.16320125043575037
