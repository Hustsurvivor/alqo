train LeroModelPairWise
Epoch: 0, training loss: 0.5993300958243922
Epoch: 1, training loss: 0.5384996329637217
Epoch: 2, training loss: 0.5021434277398609
Epoch: 3, training loss: 0.4779201889974157
Epoch: 4, training loss: 0.4589814245320862
Epoch: 5, training loss: 0.44919527975091
Epoch: 6, training loss: 0.43752871333841503
Epoch: 7, training loss: 0.42429670659728524
Epoch: 8, training loss: 0.4180387144931305
Epoch: 9, training loss: 0.40546726784762704
Epoch: 10, training loss: 0.3966165308406273
Epoch: 11, training loss: 0.38867521229690566
Epoch: 12, training loss: 0.3824672278863221
Epoch: 13, training loss: 0.37306423006823863
Epoch: 14, training loss: 0.36873301247439105
Epoch: 15, training loss: 0.35977647374232635
Epoch: 16, training loss: 0.3514425578146852
Epoch: 17, training loss: 0.34638792457444506
Epoch: 18, training loss: 0.3366585258661435
Epoch: 19, training loss: 0.33426369286807234
Epoch: 20, training loss: 0.32713816299227366
Epoch: 21, training loss: 0.32294711016254507
Epoch: 22, training loss: 0.31653083011761374
Epoch: 23, training loss: 0.312869374994882
Epoch: 24, training loss: 0.3052406605863009
Epoch: 25, training loss: 0.3007743790690861
Epoch: 26, training loss: 0.29662399459147754
Epoch: 27, training loss: 0.29084069889842296
Epoch: 28, training loss: 0.28925163945394566
Epoch: 29, training loss: 0.2876433968332955
Epoch: 30, training loss: 0.2774235919682558
Epoch: 31, training loss: 0.2769075576021059
Epoch: 32, training loss: 0.27246265449080104
Epoch: 33, training loss: 0.2684186422729869
Epoch: 34, training loss: 0.2667502193948651
Epoch: 35, training loss: 0.26438044495588614
Epoch: 36, training loss: 0.26188951926397575
Epoch: 37, training loss: 0.2589141732317984
Epoch: 38, training loss: 0.2552811619826385
Epoch: 39, training loss: 0.25140695709505456
Epoch: 40, training loss: 0.25404383727693436
Epoch: 41, training loss: 0.24868323973283066
Epoch: 42, training loss: 0.24759433077725362
Epoch: 43, training loss: 0.24313977046342716
Epoch: 44, training loss: 0.24328068286223933
Epoch: 45, training loss: 0.23768834327842156
Epoch: 46, training loss: 0.23762430435002638
Epoch: 47, training loss: 0.2391716230512587
Epoch: 48, training loss: 0.23702395781626268
Epoch: 49, training loss: 0.22991252029116857
Epoch: 50, training loss: 0.22710306096756125
Epoch: 51, training loss: 0.22768618530203852
Epoch: 52, training loss: 0.22920616199223645
Epoch: 53, training loss: 0.2204861213103914
Epoch: 54, training loss: 0.22350319581792472
Epoch: 55, training loss: 0.22271758220540844
Epoch: 56, training loss: 0.2204748995751769
Epoch: 57, training loss: 0.2199512734160602
Epoch: 58, training loss: 0.21609623428004004
Epoch: 59, training loss: 0.21673777137763342
Epoch: 60, training loss: 0.21426520132927404
Epoch: 61, training loss: 0.2107831132841457
Epoch: 62, training loss: 0.21508627287918985
Epoch: 63, training loss: 0.20938308273183043
Epoch: 64, training loss: 0.20954986258612998
Epoch: 65, training loss: 0.20401471921983744
Epoch: 66, training loss: 0.2050274983505248
Epoch: 67, training loss: 0.2028293533338372
Epoch: 68, training loss: 0.20562010684817048
Epoch: 69, training loss: 0.20354400509227547
Epoch: 70, training loss: 0.20095917729829174
Epoch: 71, training loss: 0.1968543537567528
Epoch: 72, training loss: 0.1997069310627863
Epoch: 73, training loss: 0.19255874561486272
Epoch: 74, training loss: 0.1934184264100848
Epoch: 75, training loss: 0.19878785296565696
Epoch: 76, training loss: 0.19759498782572074
Epoch: 77, training loss: 0.1906165875991521
Epoch: 78, training loss: 0.19263213323790682
Epoch: 79, training loss: 0.19047759959491126
Epoch: 80, training loss: 0.18898374245176078
Epoch: 81, training loss: 0.1871809312408722
Epoch: 82, training loss: 0.18700130330178066
Epoch: 83, training loss: 0.18637534608046508
Epoch: 84, training loss: 0.18818949732378756
Epoch: 85, training loss: 0.1816342716733532
Epoch: 86, training loss: 0.18901246841305197
Epoch: 87, training loss: 0.17981155918563466
Epoch: 88, training loss: 0.1826179515824843
Epoch: 89, training loss: 0.17751149801908234
Epoch: 90, training loss: 0.18039291078699268
Epoch: 91, training loss: 0.17449398182990608
Epoch: 92, training loss: 0.17416550914296539
Epoch: 93, training loss: 0.1746072954440247
Epoch: 94, training loss: 0.1768086185039489
Epoch: 95, training loss: 0.17510317157940258
Epoch: 96, training loss: 0.1753987857938954
Epoch: 97, training loss: 0.17304815917739771
Epoch: 98, training loss: 0.17320328242936422
Epoch: 99, training loss: 0.17200241709785624
