train LeroModelPairWise
Epoch: 0, training loss: 0.6010311878670117
Epoch: 1, training loss: 0.5365857436862455
Epoch: 2, training loss: 0.5035643131245681
Epoch: 3, training loss: 0.48017934041758964
Epoch: 4, training loss: 0.4665142975633015
Epoch: 5, training loss: 0.4532766087662222
Epoch: 6, training loss: 0.4375070211551168
Epoch: 7, training loss: 0.42868477033033886
Epoch: 8, training loss: 0.41697631079182823
Epoch: 9, training loss: 0.41101569113490266
Epoch: 10, training loss: 0.39820605895140826
Epoch: 11, training loss: 0.3902008814675343
Epoch: 12, training loss: 0.38199801594949057
Epoch: 13, training loss: 0.375270298901322
Epoch: 14, training loss: 0.3660736302855432
Epoch: 15, training loss: 0.35680054278714457
Epoch: 16, training loss: 0.3541835838760929
Epoch: 17, training loss: 0.34308344894914194
Epoch: 18, training loss: 0.3413393122545034
Epoch: 19, training loss: 0.3318772086531928
Epoch: 20, training loss: 0.32518913178455144
Epoch: 21, training loss: 0.32189000247036237
Epoch: 22, training loss: 0.3144124716192768
Epoch: 23, training loss: 0.3100193952053005
Epoch: 24, training loss: 0.3052552537733186
Epoch: 25, training loss: 0.29717374032163
Epoch: 26, training loss: 0.29252277247077424
Epoch: 27, training loss: 0.29065047332422417
Epoch: 28, training loss: 0.28829905734482303
Epoch: 29, training loss: 0.28392182958013584
Epoch: 30, training loss: 0.2770091595479555
Epoch: 31, training loss: 0.2765550372844687
Epoch: 32, training loss: 0.26734558741437753
Epoch: 33, training loss: 0.26665421767316305
Epoch: 34, training loss: 0.26178266727314464
Epoch: 35, training loss: 0.26411699411945894
Epoch: 36, training loss: 0.25851522068537647
Epoch: 37, training loss: 0.2531814899603391
Epoch: 38, training loss: 0.2486619435892132
Epoch: 39, training loss: 0.24903964425770939
Epoch: 40, training loss: 0.24736706816723766
Epoch: 41, training loss: 0.24520323522811804
Epoch: 42, training loss: 0.237280274891997
Epoch: 43, training loss: 0.23795467468951276
Epoch: 44, training loss: 0.2392574194748087
Epoch: 45, training loss: 0.23241632737352622
Epoch: 46, training loss: 0.22949234168900778
Epoch: 47, training loss: 0.22992034940065545
Epoch: 48, training loss: 0.2245910973370586
Epoch: 49, training loss: 0.22450185527106112
Epoch: 50, training loss: 0.22331275778126197
Epoch: 51, training loss: 0.22281392728192984
Epoch: 52, training loss: 0.21560402447264337
Epoch: 53, training loss: 0.2215225451737549
Epoch: 54, training loss: 0.21625475567840613
Epoch: 55, training loss: 0.21723698079767717
Epoch: 56, training loss: 0.21291178673151115
Epoch: 57, training loss: 0.21457039556712976
Epoch: 58, training loss: 0.2113236703887036
Epoch: 59, training loss: 0.2069125451896456
Epoch: 60, training loss: 0.20546544966618893
Epoch: 61, training loss: 0.20303941968602254
Epoch: 62, training loss: 0.2049182145157707
Epoch: 63, training loss: 0.20326040961625502
Epoch: 64, training loss: 0.20154704859418837
Epoch: 65, training loss: 0.19915423708040184
Epoch: 66, training loss: 0.19668242971208585
Epoch: 67, training loss: 0.19402852401791007
Epoch: 68, training loss: 0.18935857334640735
Epoch: 69, training loss: 0.1913109107576748
Epoch: 70, training loss: 0.19149250440088494
Epoch: 71, training loss: 0.19109609904823163
Epoch: 72, training loss: 0.19785534297734772
Epoch: 73, training loss: 0.18973463298854618
Epoch: 74, training loss: 0.19018209045299356
Epoch: 75, training loss: 0.18554474755950354
Epoch: 76, training loss: 0.1830108144597404
Epoch: 77, training loss: 0.18451708794977992
Epoch: 78, training loss: 0.1891284874005449
Epoch: 79, training loss: 0.1826069230318528
Epoch: 80, training loss: 0.1858236131081086
Epoch: 81, training loss: 0.17640063325320068
Epoch: 82, training loss: 0.176820450973345
Epoch: 83, training loss: 0.18337767841875088
Epoch: 84, training loss: 0.1775764910526007
Epoch: 85, training loss: 0.17215435934458187
Epoch: 86, training loss: 0.17712541248223426
Epoch: 87, training loss: 0.1733959157882428
Epoch: 88, training loss: 0.174559311564695
Epoch: 89, training loss: 0.17383760381433144
Epoch: 90, training loss: 0.171915877022285
Epoch: 91, training loss: 0.1720167782998462
Epoch: 92, training loss: 0.17005445442380207
Epoch: 93, training loss: 0.17154563202297346
Epoch: 94, training loss: 0.16900856476106468
Epoch: 95, training loss: 0.16721676872593766
Epoch: 96, training loss: 0.16731074240726582
Epoch: 97, training loss: 0.16490963468650136
Epoch: 98, training loss: 0.16483414174807665
Epoch: 99, training loss: 0.16215000359667847
