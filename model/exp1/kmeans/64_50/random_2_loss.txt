train LeroModelPairWise
Epoch: 0, training loss: 0.6046337242417827
Epoch: 1, training loss: 0.5384958499895888
Epoch: 2, training loss: 0.5038712678853349
Epoch: 3, training loss: 0.4823818052495565
Epoch: 4, training loss: 0.4671728687470949
Epoch: 5, training loss: 0.4495874502572978
Epoch: 6, training loss: 0.4390254136043353
Epoch: 7, training loss: 0.4274295959720289
Epoch: 8, training loss: 0.4197134027732941
Epoch: 9, training loss: 0.4142963799331868
Epoch: 10, training loss: 0.40119732279914727
Epoch: 11, training loss: 0.3931142141443468
Epoch: 12, training loss: 0.38779517156582255
Epoch: 13, training loss: 0.3805967550928889
Epoch: 14, training loss: 0.367866254897382
Epoch: 15, training loss: 0.3658039621535041
Epoch: 16, training loss: 0.35741660630323424
Epoch: 17, training loss: 0.3542012979855601
Epoch: 18, training loss: 0.34503903269598263
Epoch: 19, training loss: 0.3376674984210399
Epoch: 20, training loss: 0.33106256460604483
Epoch: 21, training loss: 0.3296824596414408
Epoch: 22, training loss: 0.3215064094072788
Epoch: 23, training loss: 0.3153568394614672
Epoch: 24, training loss: 0.31105296177817154
Epoch: 25, training loss: 0.30721575097239195
Epoch: 26, training loss: 0.30251448270343995
Epoch: 27, training loss: 0.29411437871280455
Epoch: 28, training loss: 0.2922764425224229
Epoch: 29, training loss: 0.28085765664046675
Epoch: 30, training loss: 0.2813333228144079
Epoch: 31, training loss: 0.27751386430212
Epoch: 32, training loss: 0.2733846531809711
Epoch: 33, training loss: 0.27014763619202714
Epoch: 34, training loss: 0.2668666810170191
Epoch: 35, training loss: 0.2642094325010288
Epoch: 36, training loss: 0.25898953162309896
Epoch: 37, training loss: 0.25170091541173945
Epoch: 38, training loss: 0.2528095996853842
Epoch: 39, training loss: 0.24992711868419568
Epoch: 40, training loss: 0.24580369504523164
Epoch: 41, training loss: 0.24688301011708347
Epoch: 42, training loss: 0.24484638588410393
Epoch: 43, training loss: 0.24288435659278365
Epoch: 44, training loss: 0.23744151530692503
Epoch: 45, training loss: 0.23474101519798887
Epoch: 46, training loss: 0.23180422854479588
Epoch: 47, training loss: 0.2267302492081541
Epoch: 48, training loss: 0.22458707342335957
Epoch: 49, training loss: 0.2261784453655149
Epoch: 50, training loss: 0.22685950345145434
Epoch: 51, training loss: 0.2216005375284488
Epoch: 52, training loss: 0.22189369066777534
Epoch: 53, training loss: 0.218162586600059
Epoch: 54, training loss: 0.2116919247675444
Epoch: 55, training loss: 0.21356696198948294
Epoch: 56, training loss: 0.208858108064181
Epoch: 57, training loss: 0.2137447457282375
Epoch: 58, training loss: 0.2087866558160152
Epoch: 59, training loss: 0.21179811107672505
Epoch: 60, training loss: 0.2046624102035883
Epoch: 61, training loss: 0.20436872999752548
Epoch: 62, training loss: 0.20486694094251862
Epoch: 63, training loss: 0.20644915372119768
Epoch: 64, training loss: 0.20012554013267458
Epoch: 65, training loss: 0.19788735261563203
Epoch: 66, training loss: 0.19619307858668214
Epoch: 67, training loss: 0.1931771998779828
Epoch: 68, training loss: 0.19311982421296148
Epoch: 69, training loss: 0.19863352840161141
Epoch: 70, training loss: 0.19546165053728057
Epoch: 71, training loss: 0.19260589751589666
Epoch: 72, training loss: 0.19343938227957558
Epoch: 73, training loss: 0.1865861383289382
Epoch: 74, training loss: 0.19030335264143403
Epoch: 75, training loss: 0.1863062651287385
Epoch: 76, training loss: 0.18625555225390122
Epoch: 77, training loss: 0.18189322641385913
Epoch: 78, training loss: 0.18529943603064944
Epoch: 79, training loss: 0.18324239917085408
Epoch: 80, training loss: 0.1813646639806113
Epoch: 81, training loss: 0.1797961946423715
Epoch: 82, training loss: 0.1796658946597848
Epoch: 83, training loss: 0.18426333171698187
Epoch: 84, training loss: 0.17744858168868494
Epoch: 85, training loss: 0.1768941077506219
Epoch: 86, training loss: 0.1753422808428731
Epoch: 87, training loss: 0.1755623549574812
Epoch: 88, training loss: 0.17407308515714598
Epoch: 89, training loss: 0.17617823120689205
Epoch: 90, training loss: 0.1683995428871772
Epoch: 91, training loss: 0.1741348302595455
Epoch: 92, training loss: 0.169625321198383
Epoch: 93, training loss: 0.17228829167749918
Epoch: 94, training loss: 0.16713895558861633
Epoch: 95, training loss: 0.16512670642198782
Epoch: 96, training loss: 0.16944018042547823
Epoch: 97, training loss: 0.16718686092097554
Epoch: 98, training loss: 0.1659092293415627
Epoch: 99, training loss: 0.16398056331217725
