train LeroModelPairWise
Epoch: 0, training loss: 0.5954134049895653
Epoch: 1, training loss: 0.5350116950546612
Epoch: 2, training loss: 0.5052614913672244
Epoch: 3, training loss: 0.4851137261148833
Epoch: 4, training loss: 0.4688404340342478
Epoch: 5, training loss: 0.45768553182527544
Epoch: 6, training loss: 0.44311898879203376
Epoch: 7, training loss: 0.4339140417552271
Epoch: 8, training loss: 0.4239889931540201
Epoch: 9, training loss: 0.4198585073780189
Epoch: 10, training loss: 0.4088960203673686
Epoch: 11, training loss: 0.3996199888376446
Epoch: 12, training loss: 0.39099373850259433
Epoch: 13, training loss: 0.3848052585092636
Epoch: 14, training loss: 0.3826002072663819
Epoch: 15, training loss: 0.37420525182642994
Epoch: 16, training loss: 0.36434989680385377
Epoch: 17, training loss: 0.3587550557484538
Epoch: 18, training loss: 0.3558568727123443
Epoch: 19, training loss: 0.3523372838277062
Epoch: 20, training loss: 0.34158414065679266
Epoch: 21, training loss: 0.3399069829835213
Epoch: 22, training loss: 0.3338758809811037
Epoch: 23, training loss: 0.3321340490635603
Epoch: 24, training loss: 0.319159718701119
Epoch: 25, training loss: 0.32106728190896483
Epoch: 26, training loss: 0.3149864324216747
Epoch: 27, training loss: 0.308991872702461
Epoch: 28, training loss: 0.3065789101711129
Epoch: 29, training loss: 0.2995308815352356
Epoch: 30, training loss: 0.2973098056739622
Epoch: 31, training loss: 0.2913966941925429
Epoch: 32, training loss: 0.285405219876639
Epoch: 33, training loss: 0.28493003397972033
Epoch: 34, training loss: 0.2782868794844809
Epoch: 35, training loss: 0.2761868172898793
Epoch: 36, training loss: 0.2760840901135383
Epoch: 37, training loss: 0.26801134977577096
Epoch: 38, training loss: 0.26991507736301873
Epoch: 39, training loss: 0.26468550993963136
Epoch: 40, training loss: 0.26440678454829447
Epoch: 41, training loss: 0.26000609779668415
Epoch: 42, training loss: 0.25441856088988046
Epoch: 43, training loss: 0.2504009655459332
Epoch: 44, training loss: 0.25320177417093387
Epoch: 45, training loss: 0.2516422218299073
Epoch: 46, training loss: 0.2471411172394173
Epoch: 47, training loss: 0.24403950497403334
Epoch: 48, training loss: 0.24109850419805048
Epoch: 49, training loss: 0.24137648005505233
Epoch: 50, training loss: 0.23941252001616167
Epoch: 51, training loss: 0.236480682056292
Epoch: 52, training loss: 0.23725400744500139
Epoch: 53, training loss: 0.22944252536223483
Epoch: 54, training loss: 0.2293488314154653
Epoch: 55, training loss: 0.22825532589498035
Epoch: 56, training loss: 0.2305992397762473
Epoch: 57, training loss: 0.22458993619886566
Epoch: 58, training loss: 0.22099201168223043
Epoch: 59, training loss: 0.22438629988311198
Epoch: 60, training loss: 0.21906452896539744
Epoch: 61, training loss: 0.21841064197636034
Epoch: 62, training loss: 0.21824606241870081
Epoch: 63, training loss: 0.21654967275343184
Epoch: 64, training loss: 0.21293812668333512
Epoch: 65, training loss: 0.21479181230623232
Epoch: 66, training loss: 0.21212774387037164
Epoch: 67, training loss: 0.20820301614971284
Epoch: 68, training loss: 0.20764785675852293
Epoch: 69, training loss: 0.20274160003731628
Epoch: 70, training loss: 0.20651380081198664
Epoch: 71, training loss: 0.2057745005250889
Epoch: 72, training loss: 0.2061666247474062
Epoch: 73, training loss: 0.20252845124286808
Epoch: 74, training loss: 0.19755669347551674
Epoch: 75, training loss: 0.20306664157485707
Epoch: 76, training loss: 0.1980887953709316
Epoch: 77, training loss: 0.19714672809890665
Epoch: 78, training loss: 0.19305149695313667
Epoch: 79, training loss: 0.19389749085472452
Epoch: 80, training loss: 0.19229715136110917
Epoch: 81, training loss: 0.19502753404049578
Epoch: 82, training loss: 0.19285175452387981
Epoch: 83, training loss: 0.1884945476802223
Epoch: 84, training loss: 0.1897457005654037
Epoch: 85, training loss: 0.18865410929520135
Epoch: 86, training loss: 0.18224905970952604
Epoch: 87, training loss: 0.19066661528873965
Epoch: 88, training loss: 0.18315691411135473
Epoch: 89, training loss: 0.18389171092573095
Epoch: 90, training loss: 0.18369125814854959
Epoch: 91, training loss: 0.1838096922721904
Epoch: 92, training loss: 0.1827881294369567
Epoch: 93, training loss: 0.1793817652878988
Epoch: 94, training loss: 0.18141296349717856
Epoch: 95, training loss: 0.17727251940563646
Epoch: 96, training loss: 0.17909994964720832
Epoch: 97, training loss: 0.17688823948546903
Epoch: 98, training loss: 0.17844299842039846
Epoch: 99, training loss: 0.17819254080276
