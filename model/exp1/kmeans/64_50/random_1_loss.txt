train LeroModelPairWise
Epoch: 0, training loss: 0.6010809330335134
Epoch: 1, training loss: 0.5352125776173815
Epoch: 2, training loss: 0.5055059005950153
Epoch: 3, training loss: 0.4895588275154558
Epoch: 4, training loss: 0.4746574138251252
Epoch: 5, training loss: 0.4596229087830804
Epoch: 6, training loss: 0.4478061020307367
Epoch: 7, training loss: 0.4377359166514054
Epoch: 8, training loss: 0.42613024302509506
Epoch: 9, training loss: 0.42118210293659536
Epoch: 10, training loss: 0.41355728548945675
Epoch: 11, training loss: 0.40460074292340076
Epoch: 12, training loss: 0.3969219125764048
Epoch: 13, training loss: 0.3908928497784081
Epoch: 14, training loss: 0.38102502238523744
Epoch: 15, training loss: 0.37826281471438794
Epoch: 16, training loss: 0.36826369892312616
Epoch: 17, training loss: 0.3647481924905127
Epoch: 18, training loss: 0.35885180190978766
Epoch: 19, training loss: 0.35443262342130344
Epoch: 20, training loss: 0.348599897190168
Epoch: 21, training loss: 0.34121381029168135
Epoch: 22, training loss: 0.33360620063509133
Epoch: 23, training loss: 0.3337579908038201
Epoch: 24, training loss: 0.32864580742287686
Epoch: 25, training loss: 0.32102985475819584
Epoch: 26, training loss: 0.31945205088103107
Epoch: 27, training loss: 0.31452506499864163
Epoch: 28, training loss: 0.30800211939657074
Epoch: 29, training loss: 0.3000326645018978
Epoch: 30, training loss: 0.297606320316706
Epoch: 31, training loss: 0.29546885738657996
Epoch: 32, training loss: 0.29387474806779357
Epoch: 33, training loss: 0.28832139646885957
Epoch: 34, training loss: 0.2846732299483977
Epoch: 35, training loss: 0.2793305588269606
Epoch: 36, training loss: 0.27582437624205386
Epoch: 37, training loss: 0.27307363718231137
Epoch: 38, training loss: 0.2732063600114117
Epoch: 39, training loss: 0.2663073372563623
Epoch: 40, training loss: 0.26415564030542193
Epoch: 41, training loss: 0.2598608759408536
Epoch: 42, training loss: 0.2594542471532613
Epoch: 43, training loss: 0.2541730580908041
Epoch: 44, training loss: 0.2541819833891445
Epoch: 45, training loss: 0.24682259556815905
Epoch: 46, training loss: 0.24806207849672213
Epoch: 47, training loss: 0.24401277529387147
Epoch: 48, training loss: 0.2428245418568898
Epoch: 49, training loss: 0.24237626905830864
Epoch: 50, training loss: 0.23969247080266168
Epoch: 51, training loss: 0.23259126107140643
Epoch: 52, training loss: 0.2372526619754277
Epoch: 53, training loss: 0.23515763533873188
Epoch: 54, training loss: 0.23564686336913826
Epoch: 55, training loss: 0.2277851699283951
Epoch: 56, training loss: 0.22453570025746708
Epoch: 57, training loss: 0.22772582855628584
Epoch: 58, training loss: 0.22120641897254717
Epoch: 59, training loss: 0.2223033230415066
Epoch: 60, training loss: 0.22388079410745687
Epoch: 61, training loss: 0.2146293693095723
Epoch: 62, training loss: 0.21682334169634546
Epoch: 63, training loss: 0.21531191629210975
Epoch: 64, training loss: 0.21490369208181592
Epoch: 65, training loss: 0.20805728608455742
Epoch: 66, training loss: 0.21780437734501998
Epoch: 67, training loss: 0.2040382817738391
Epoch: 68, training loss: 0.20915970971595002
Epoch: 69, training loss: 0.2089518486670487
Epoch: 70, training loss: 0.20618171577949432
Epoch: 71, training loss: 0.20745933121210938
Epoch: 72, training loss: 0.20519640262974892
Epoch: 73, training loss: 0.2010844810651357
Epoch: 74, training loss: 0.20046874017552765
Epoch: 75, training loss: 0.19826714566203055
Epoch: 76, training loss: 0.2016888672938473
Epoch: 77, training loss: 0.1944126308205213
Epoch: 78, training loss: 0.19463933570192007
Epoch: 79, training loss: 0.19302236296007694
Epoch: 80, training loss: 0.19276959334656063
Epoch: 81, training loss: 0.19460238781507738
Epoch: 82, training loss: 0.1942439058215193
Epoch: 83, training loss: 0.19188811574952594
Epoch: 84, training loss: 0.1916731677797771
Epoch: 85, training loss: 0.19053735228679197
Epoch: 86, training loss: 0.18470462029830212
Epoch: 87, training loss: 0.18804387048286147
Epoch: 88, training loss: 0.18505145741279197
Epoch: 89, training loss: 0.1872925059882149
Epoch: 90, training loss: 0.18458161626088299
Epoch: 91, training loss: 0.180486650276832
Epoch: 92, training loss: 0.18078823890487897
Epoch: 93, training loss: 0.1822318796366008
Epoch: 94, training loss: 0.17800540881346866
Epoch: 95, training loss: 0.17736827428326693
Epoch: 96, training loss: 0.1805049128909179
Epoch: 97, training loss: 0.17917684319442806
Epoch: 98, training loss: 0.17606925866891027
Epoch: 99, training loss: 0.17319293908936526
