train LeroModelPairWise
Epoch: 0, training loss: 0.6023622744040773
Epoch: 1, training loss: 0.5330361944256904
Epoch: 2, training loss: 0.5067001361662062
Epoch: 3, training loss: 0.48602157265049906
Epoch: 4, training loss: 0.4640913199685127
Epoch: 5, training loss: 0.4576708444627966
Epoch: 6, training loss: 0.4436795308698473
Epoch: 7, training loss: 0.4331660457237879
Epoch: 8, training loss: 0.4250763852119197
Epoch: 9, training loss: 0.4159967200396192
Epoch: 10, training loss: 0.40658951590609743
Epoch: 11, training loss: 0.3990489875905161
Epoch: 12, training loss: 0.3932836303783783
Epoch: 13, training loss: 0.3861129190379194
Epoch: 14, training loss: 0.3773602433939885
Epoch: 15, training loss: 0.374007008301278
Epoch: 16, training loss: 0.37017003927751035
Epoch: 17, training loss: 0.3599311051912541
Epoch: 18, training loss: 0.3535716705329577
Epoch: 19, training loss: 0.35031815048395143
Epoch: 20, training loss: 0.3443945673007142
Epoch: 21, training loss: 0.34015700052348546
Epoch: 22, training loss: 0.3353227041486982
Epoch: 23, training loss: 0.3274121632863098
Epoch: 24, training loss: 0.3227515150101481
Epoch: 25, training loss: 0.3195848817532206
Epoch: 26, training loss: 0.3129880075464911
Epoch: 27, training loss: 0.3084665294169588
Epoch: 28, training loss: 0.30259671697423085
Epoch: 29, training loss: 0.29873493208997376
Epoch: 30, training loss: 0.2992244593292024
Epoch: 31, training loss: 0.2922531634960228
Epoch: 32, training loss: 0.2869542194613178
Epoch: 33, training loss: 0.28217945783013715
Epoch: 34, training loss: 0.282898817586339
Epoch: 35, training loss: 0.2749372989295852
Epoch: 36, training loss: 0.27448062951050767
Epoch: 37, training loss: 0.2710276426300599
Epoch: 38, training loss: 0.2679016052940301
Epoch: 39, training loss: 0.26419151845624345
Epoch: 40, training loss: 0.26268399227127076
Epoch: 41, training loss: 0.2607652055792677
Epoch: 42, training loss: 0.2586355802859272
Epoch: 43, training loss: 0.2534762411606348
Epoch: 44, training loss: 0.25231727680749494
Epoch: 45, training loss: 0.24884932089514356
Epoch: 46, training loss: 0.24631791854764132
Epoch: 47, training loss: 0.24398814352873416
Epoch: 48, training loss: 0.24255570360171097
Epoch: 49, training loss: 0.2388722567483146
Epoch: 50, training loss: 0.23537186011618075
Epoch: 51, training loss: 0.2305427913561382
Epoch: 52, training loss: 0.23101248206913513
Epoch: 53, training loss: 0.22790186928404074
Epoch: 54, training loss: 0.22605646080066838
Epoch: 55, training loss: 0.22298479103619143
Epoch: 56, training loss: 0.22600724039239908
Epoch: 57, training loss: 0.2233306513985961
Epoch: 58, training loss: 0.22261477985841774
Epoch: 59, training loss: 0.21623119733376286
Epoch: 60, training loss: 0.21704486889425423
Epoch: 61, training loss: 0.2150040034776345
Epoch: 62, training loss: 0.21507802398064185
Epoch: 63, training loss: 0.21317820703867071
Epoch: 64, training loss: 0.21062412029829425
Epoch: 65, training loss: 0.20880097573516268
Epoch: 66, training loss: 0.20797302814352164
Epoch: 67, training loss: 0.20796097147722814
Epoch: 68, training loss: 0.20665543902990588
Epoch: 69, training loss: 0.20341919368200917
Epoch: 70, training loss: 0.2013567264515475
Epoch: 71, training loss: 0.20272354078988927
Epoch: 72, training loss: 0.20009295776654717
Epoch: 73, training loss: 0.20117563094658486
Epoch: 74, training loss: 0.1975636513038906
Epoch: 75, training loss: 0.19230579661109976
Epoch: 76, training loss: 0.19018401682099295
Epoch: 77, training loss: 0.1925595395779857
Epoch: 78, training loss: 0.18792011516677248
Epoch: 79, training loss: 0.1959019612240793
Epoch: 80, training loss: 0.19323745247516214
Epoch: 81, training loss: 0.18787237804595278
Epoch: 82, training loss: 0.1878554656503577
Epoch: 83, training loss: 0.18664993609483585
Epoch: 84, training loss: 0.18630752128867034
Epoch: 85, training loss: 0.1820859855667508
Epoch: 86, training loss: 0.1810910020377322
Epoch: 87, training loss: 0.18174807395756065
Epoch: 88, training loss: 0.17981338764301513
Epoch: 89, training loss: 0.18045703919242745
Epoch: 90, training loss: 0.177136209420273
Epoch: 91, training loss: 0.17844349381198982
Epoch: 92, training loss: 0.17830717877374364
Epoch: 93, training loss: 0.17732492354008814
Epoch: 94, training loss: 0.17514439657229394
Epoch: 95, training loss: 0.17494996919687777
Epoch: 96, training loss: 0.1755135941705484
Epoch: 97, training loss: 0.1713078648870221
Epoch: 98, training loss: 0.17107228287860113
Epoch: 99, training loss: 0.16933467284666848
