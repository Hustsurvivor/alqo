train LeroModelPairWise
Epoch: 0, training loss: 0.6193165345257039
Epoch: 1, training loss: 0.5572088456194623
Epoch: 2, training loss: 0.5232239665200704
Epoch: 3, training loss: 0.5051441749326272
Epoch: 4, training loss: 0.4880275827450016
Epoch: 5, training loss: 0.4753821325806976
Epoch: 6, training loss: 0.4659174628674058
Epoch: 7, training loss: 0.4532423847357341
Epoch: 8, training loss: 0.44252571292463827
Epoch: 9, training loss: 0.43668436765478214
Epoch: 10, training loss: 0.42211733937748924
Epoch: 11, training loss: 0.41698986849359093
Epoch: 12, training loss: 0.40940488681765314
Epoch: 13, training loss: 0.39694583956595614
Epoch: 14, training loss: 0.389372918464094
Epoch: 15, training loss: 0.3829748768855984
Epoch: 16, training loss: 0.37564003762627424
Epoch: 17, training loss: 0.36566632506479185
Epoch: 18, training loss: 0.36326034743921126
Epoch: 19, training loss: 0.3564044980734234
Epoch: 20, training loss: 0.3488530225800124
Epoch: 21, training loss: 0.33806224832754733
Epoch: 22, training loss: 0.33583802617665287
Epoch: 23, training loss: 0.3303646668655355
Epoch: 24, training loss: 0.32112205228232504
Epoch: 25, training loss: 0.3149394578101077
Epoch: 26, training loss: 0.3061719853490697
Epoch: 27, training loss: 0.3070767619409942
Epoch: 28, training loss: 0.2981274433099548
Epoch: 29, training loss: 0.29039398624161583
Epoch: 30, training loss: 0.286357203171671
Epoch: 31, training loss: 0.283588968427734
Epoch: 32, training loss: 0.2748670896446752
Epoch: 33, training loss: 0.269972947980437
Epoch: 34, training loss: 0.27001787885039624
Epoch: 35, training loss: 0.2609120647822401
Epoch: 36, training loss: 0.2557638033892517
Epoch: 37, training loss: 0.25620387090277197
Epoch: 38, training loss: 0.2537718907512652
Epoch: 39, training loss: 0.24727719597915587
Epoch: 40, training loss: 0.24437552707489332
Epoch: 41, training loss: 0.24106316220080834
Epoch: 42, training loss: 0.23546194980921784
Epoch: 43, training loss: 0.24078122548398656
Epoch: 44, training loss: 0.22856342643449998
Epoch: 45, training loss: 0.22513218107563762
Epoch: 46, training loss: 0.2227772401672745
Epoch: 47, training loss: 0.22138420769438186
Epoch: 48, training loss: 0.2210667049334589
Epoch: 49, training loss: 0.2155443181133232
Epoch: 50, training loss: 0.2174900165864173
Epoch: 51, training loss: 0.2152321755335677
Epoch: 52, training loss: 0.2116603603177341
Epoch: 53, training loss: 0.20677993625754035
Epoch: 54, training loss: 0.20483860176471755
Epoch: 55, training loss: 0.19754850340075156
Epoch: 56, training loss: 0.20270532529796095
Epoch: 57, training loss: 0.19943221718546222
Epoch: 58, training loss: 0.1974751933356599
Epoch: 59, training loss: 0.1928133819681932
Epoch: 60, training loss: 0.194135461282508
Epoch: 61, training loss: 0.18973861998759786
Epoch: 62, training loss: 0.19271743118463927
Epoch: 63, training loss: 0.19235889269419662
Epoch: 64, training loss: 0.18465162553393727
Epoch: 65, training loss: 0.18490426605228785
Epoch: 66, training loss: 0.18594785866257643
Epoch: 67, training loss: 0.17800491115584316
Epoch: 68, training loss: 0.18292643177420004
Epoch: 69, training loss: 0.1785135413089005
Epoch: 70, training loss: 0.1760803848781892
Epoch: 71, training loss: 0.17477822513018781
Epoch: 72, training loss: 0.1789619812349597
Epoch: 73, training loss: 0.16984698740342366
Epoch: 74, training loss: 0.17223209102198486
Epoch: 75, training loss: 0.16809839330510787
Epoch: 76, training loss: 0.17124579042366356
Epoch: 77, training loss: 0.16613050108946312
Epoch: 78, training loss: 0.16461149173513276
Epoch: 79, training loss: 0.1647227707552671
Epoch: 80, training loss: 0.16500089193459344
Epoch: 81, training loss: 0.1581655632957551
Epoch: 82, training loss: 0.16143783036656184
Epoch: 83, training loss: 0.16329819231201992
Epoch: 84, training loss: 0.1664021572275384
Epoch: 85, training loss: 0.15539736031183732
Epoch: 86, training loss: 0.16048102711336512
Epoch: 87, training loss: 0.1531832164535748
Epoch: 88, training loss: 0.15367347494915365
Epoch: 89, training loss: 0.15611024260769651
Epoch: 90, training loss: 0.15017241331999992
Epoch: 91, training loss: 0.15283260229910667
Epoch: 92, training loss: 0.15201360431542
Epoch: 93, training loss: 0.1520500488064626
Epoch: 94, training loss: 0.15206231857907665
Epoch: 95, training loss: 0.14828677160274478
Epoch: 96, training loss: 0.14555398666303185
Epoch: 97, training loss: 0.14411729389814226
Epoch: 98, training loss: 0.14608216485681513
Epoch: 99, training loss: 0.14102515447821015
