train LeroModelPairWise
Epoch: 0, training loss: 0.5997122240639365
Epoch: 1, training loss: 0.5389598777425954
Epoch: 2, training loss: 0.5093326925397754
Epoch: 3, training loss: 0.4876191971387287
Epoch: 4, training loss: 0.4739213498489047
Epoch: 5, training loss: 0.45866059239307166
Epoch: 6, training loss: 0.4481995714988008
Epoch: 7, training loss: 0.4387865388306108
Epoch: 8, training loss: 0.42915780038992607
Epoch: 9, training loss: 0.42091431177576144
Epoch: 10, training loss: 0.4114409489224656
Epoch: 11, training loss: 0.4027984571839837
Epoch: 12, training loss: 0.3973074959794382
Epoch: 13, training loss: 0.3918496214928872
Epoch: 14, training loss: 0.3814774311221784
Epoch: 15, training loss: 0.3750024131193043
Epoch: 16, training loss: 0.3732860372836733
Epoch: 17, training loss: 0.35962870212185555
Epoch: 18, training loss: 0.35996405026922434
Epoch: 19, training loss: 0.35327485381164053
Epoch: 20, training loss: 0.34796775711802885
Epoch: 21, training loss: 0.33935495049027514
Epoch: 22, training loss: 0.33219201604372234
Epoch: 23, training loss: 0.32750146273922914
Epoch: 24, training loss: 0.3231458079310627
Epoch: 25, training loss: 0.3197591932155921
Epoch: 26, training loss: 0.3146976730119913
Epoch: 27, training loss: 0.3091674495409151
Epoch: 28, training loss: 0.3037298280094837
Epoch: 29, training loss: 0.30233982846003066
Epoch: 30, training loss: 0.29474052334792045
Epoch: 31, training loss: 0.29381233981127924
Epoch: 32, training loss: 0.2862715791035884
Epoch: 33, training loss: 0.28607919839369933
Epoch: 34, training loss: 0.2822488035056031
Epoch: 35, training loss: 0.27894866000997376
Epoch: 36, training loss: 0.2751692973234017
Epoch: 37, training loss: 0.26875380628193796
Epoch: 38, training loss: 0.26990907756290056
Epoch: 39, training loss: 0.26319219751853695
Epoch: 40, training loss: 0.2610599944800928
Epoch: 41, training loss: 0.26165117816891276
Epoch: 42, training loss: 0.25683478134512955
Epoch: 43, training loss: 0.2520794437022656
Epoch: 44, training loss: 0.252933678988733
Epoch: 45, training loss: 0.2475144288926366
Epoch: 46, training loss: 0.24624039279494508
Epoch: 47, training loss: 0.24064999725428568
Epoch: 48, training loss: 0.24381350143506533
Epoch: 49, training loss: 0.23785809300653393
Epoch: 50, training loss: 0.23786226604862318
Epoch: 51, training loss: 0.2351607569913999
Epoch: 52, training loss: 0.23343922690241695
Epoch: 53, training loss: 0.22859501405360186
Epoch: 54, training loss: 0.23528273697909508
Epoch: 55, training loss: 0.231588649797222
Epoch: 56, training loss: 0.22856127513038713
Epoch: 57, training loss: 0.2239669129033504
Epoch: 58, training loss: 0.2227902149452693
Epoch: 59, training loss: 0.22431305303988253
Epoch: 60, training loss: 0.2190895802681823
Epoch: 61, training loss: 0.21447962936066844
Epoch: 62, training loss: 0.21744758999965144
Epoch: 63, training loss: 0.2114782201095901
Epoch: 64, training loss: 0.20986298517553068
Epoch: 65, training loss: 0.212601429217532
Epoch: 66, training loss: 0.212106119107929
Epoch: 67, training loss: 0.2100034174453257
Epoch: 68, training loss: 0.20780977674398146
Epoch: 69, training loss: 0.20230014763560292
Epoch: 70, training loss: 0.20281893060762646
Epoch: 71, training loss: 0.20609025180329932
Epoch: 72, training loss: 0.204720626695523
Epoch: 73, training loss: 0.19566792817089101
Epoch: 74, training loss: 0.19627197210645816
Epoch: 75, training loss: 0.19700643305408694
Epoch: 76, training loss: 0.19727841615242298
Epoch: 77, training loss: 0.19368713134596643
Epoch: 78, training loss: 0.19440083408515313
Epoch: 79, training loss: 0.19037320848626108
Epoch: 80, training loss: 0.19162003361315577
Epoch: 81, training loss: 0.19197289575213117
Epoch: 82, training loss: 0.18656538057071126
Epoch: 83, training loss: 0.1853883785039397
Epoch: 84, training loss: 0.18894599626963324
Epoch: 85, training loss: 0.18406376013893164
Epoch: 86, training loss: 0.18670842564038728
Epoch: 87, training loss: 0.18478532134084688
Epoch: 88, training loss: 0.18506513969019156
Epoch: 89, training loss: 0.18537053012825583
Epoch: 90, training loss: 0.17774710597796764
Epoch: 91, training loss: 0.17936576135217797
Epoch: 92, training loss: 0.18026765181219723
Epoch: 93, training loss: 0.18419569973472275
Epoch: 94, training loss: 0.17562254892194792
Epoch: 95, training loss: 0.1783209422689684
Epoch: 96, training loss: 0.17514996182041784
Epoch: 97, training loss: 0.17549077716237027
Epoch: 98, training loss: 0.17079515406503035
Epoch: 99, training loss: 0.1735990386294421
