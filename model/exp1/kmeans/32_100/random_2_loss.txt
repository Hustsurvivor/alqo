train LeroModelPairWise
Epoch: 0, training loss: 0.606644622551563
Epoch: 1, training loss: 0.5474027972781914
Epoch: 2, training loss: 0.5082060347622531
Epoch: 3, training loss: 0.4910656560587172
Epoch: 4, training loss: 0.470491669537299
Epoch: 5, training loss: 0.4535246131752809
Epoch: 6, training loss: 0.4444469988129608
Epoch: 7, training loss: 0.42992180603030783
Epoch: 8, training loss: 0.42375581981682636
Epoch: 9, training loss: 0.41386052063736506
Epoch: 10, training loss: 0.4021112997185329
Epoch: 11, training loss: 0.39435667912288724
Epoch: 12, training loss: 0.3880031769631392
Epoch: 13, training loss: 0.3798652813277057
Epoch: 14, training loss: 0.37588526403435313
Epoch: 15, training loss: 0.36850717109623515
Epoch: 16, training loss: 0.3604903178427016
Epoch: 17, training loss: 0.35226988084924554
Epoch: 18, training loss: 0.35122306176827534
Epoch: 19, training loss: 0.3414673539126638
Epoch: 20, training loss: 0.3386052461663657
Epoch: 21, training loss: 0.32767378878186976
Epoch: 22, training loss: 0.3234931656916779
Epoch: 23, training loss: 0.32029328180803185
Epoch: 24, training loss: 0.31452754991245535
Epoch: 25, training loss: 0.30964302954068373
Epoch: 26, training loss: 0.30839533255715745
Epoch: 27, training loss: 0.29900896193734866
Epoch: 28, training loss: 0.2965714310316666
Epoch: 29, training loss: 0.2873584611248235
Epoch: 30, training loss: 0.2901915152346622
Epoch: 31, training loss: 0.2814882385274362
Epoch: 32, training loss: 0.2828967831015418
Epoch: 33, training loss: 0.2759668648747593
Epoch: 34, training loss: 0.2698990569911371
Epoch: 35, training loss: 0.2691344573833107
Epoch: 36, training loss: 0.26671401866258587
Epoch: 37, training loss: 0.2610101237057528
Epoch: 38, training loss: 0.25877345312037275
Epoch: 39, training loss: 0.2572738047783508
Epoch: 40, training loss: 0.24861052870881759
Epoch: 41, training loss: 0.25052792061131895
Epoch: 42, training loss: 0.2469376223968895
Epoch: 43, training loss: 0.24329297232327227
Epoch: 44, training loss: 0.23579580078944537
Epoch: 45, training loss: 0.23815698629851592
Epoch: 46, training loss: 0.23898998705228686
Epoch: 47, training loss: 0.2360608268952021
Epoch: 48, training loss: 0.23512525858012465
Epoch: 49, training loss: 0.23095762728825656
Epoch: 50, training loss: 0.2280455037208078
Epoch: 51, training loss: 0.2247521489261788
Epoch: 52, training loss: 0.22688745151316222
Epoch: 53, training loss: 0.220216099037202
Epoch: 54, training loss: 0.21642229300614768
Epoch: 55, training loss: 0.21776745823722843
Epoch: 56, training loss: 0.21459711555027142
Epoch: 57, training loss: 0.21279886306792337
Epoch: 58, training loss: 0.21222673832048422
Epoch: 59, training loss: 0.20977011651958696
Epoch: 60, training loss: 0.20417760248307198
Epoch: 61, training loss: 0.20403845727506023
Epoch: 62, training loss: 0.20839340921745542
Epoch: 63, training loss: 0.2034239269407542
Epoch: 64, training loss: 0.20110191700461874
Epoch: 65, training loss: 0.20073123980056237
Epoch: 66, training loss: 0.19655836533827095
Epoch: 67, training loss: 0.2009509557130927
Epoch: 68, training loss: 0.19565391936836649
Epoch: 69, training loss: 0.19838933891486926
Epoch: 70, training loss: 0.19325010120802213
Epoch: 71, training loss: 0.1954100779070006
Epoch: 72, training loss: 0.19175709939680294
Epoch: 73, training loss: 0.19071043096938717
Epoch: 74, training loss: 0.188051390105589
Epoch: 75, training loss: 0.185771383831189
Epoch: 76, training loss: 0.18497933474545325
Epoch: 77, training loss: 0.18572100096744132
Epoch: 78, training loss: 0.18583320689707583
Epoch: 79, training loss: 0.18362698482496528
Epoch: 80, training loss: 0.18499484017818438
Epoch: 81, training loss: 0.18049944656740347
Epoch: 82, training loss: 0.1794823829461368
Epoch: 83, training loss: 0.1777877621797417
Epoch: 84, training loss: 0.18189352683154608
Epoch: 85, training loss: 0.1769657446273523
Epoch: 86, training loss: 0.17521910196905469
Epoch: 87, training loss: 0.17523733877356176
Epoch: 88, training loss: 0.1728560369535508
Epoch: 89, training loss: 0.17429948409224016
Epoch: 90, training loss: 0.16960838604425474
Epoch: 91, training loss: 0.16796805926564312
Epoch: 92, training loss: 0.16864664490886855
Epoch: 93, training loss: 0.16462956328721823
Epoch: 94, training loss: 0.1666312380215022
Epoch: 95, training loss: 0.16843160620186642
Epoch: 96, training loss: 0.16325965725138109
Epoch: 97, training loss: 0.1668336067497341
Epoch: 98, training loss: 0.16775756323385702
Epoch: 99, training loss: 0.16783650019608232
