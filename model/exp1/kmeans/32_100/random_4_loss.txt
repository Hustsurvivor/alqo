train LeroModelPairWise
Epoch: 0, training loss: 0.6058347775118936
Epoch: 1, training loss: 0.5382002874836733
Epoch: 2, training loss: 0.5062704721281219
Epoch: 3, training loss: 0.4860978857032692
Epoch: 4, training loss: 0.46928459967735436
Epoch: 5, training loss: 0.4534856052638158
Epoch: 6, training loss: 0.4432883821507636
Epoch: 7, training loss: 0.4326295897985082
Epoch: 8, training loss: 0.4197178572697309
Epoch: 9, training loss: 0.4118103377639471
Epoch: 10, training loss: 0.4053484070431121
Epoch: 11, training loss: 0.40332031148056
Epoch: 12, training loss: 0.39051575972166847
Epoch: 13, training loss: 0.37922433944654765
Epoch: 14, training loss: 0.3786514792801791
Epoch: 15, training loss: 0.37468202367510134
Epoch: 16, training loss: 0.36400692907915866
Epoch: 17, training loss: 0.3571200775647785
Epoch: 18, training loss: 0.3516958226691493
Epoch: 19, training loss: 0.34231838261467834
Epoch: 20, training loss: 0.33835727104706664
Epoch: 21, training loss: 0.3319993653791719
Epoch: 22, training loss: 0.3297008006168072
Epoch: 23, training loss: 0.32432820407167434
Epoch: 24, training loss: 0.3134683303890869
Epoch: 25, training loss: 0.31242058637273784
Epoch: 26, training loss: 0.30744962280119253
Epoch: 27, training loss: 0.30276872304432034
Epoch: 28, training loss: 0.3031454657542603
Epoch: 29, training loss: 0.2944398791650762
Epoch: 30, training loss: 0.28821130812068485
Epoch: 31, training loss: 0.2871806112003544
Epoch: 32, training loss: 0.2853353307250911
Epoch: 33, training loss: 0.2760550009622891
Epoch: 34, training loss: 0.2751815040588279
Epoch: 35, training loss: 0.2713197474770185
Epoch: 36, training loss: 0.27228931783453364
Epoch: 37, training loss: 0.2650827118973596
Epoch: 38, training loss: 0.26567265771128384
Epoch: 39, training loss: 0.2607081884230186
Epoch: 40, training loss: 0.255689519916152
Epoch: 41, training loss: 0.25151043354809727
Epoch: 42, training loss: 0.2519468872556051
Epoch: 43, training loss: 0.24806895486264335
Epoch: 44, training loss: 0.24702451132826406
Epoch: 45, training loss: 0.24562490199176837
Epoch: 46, training loss: 0.23903481263574217
Epoch: 47, training loss: 0.23763308017016474
Epoch: 48, training loss: 0.23312954186028662
Epoch: 49, training loss: 0.23253785729038412
Epoch: 50, training loss: 0.2259223077559766
Epoch: 51, training loss: 0.2252836040630517
Epoch: 52, training loss: 0.2255694417773543
Epoch: 53, training loss: 0.2219082389419715
Epoch: 54, training loss: 0.22499746305943194
Epoch: 55, training loss: 0.21902628694569531
Epoch: 56, training loss: 0.219866143513296
Epoch: 57, training loss: 0.2146144856263023
Epoch: 58, training loss: 0.21616676253076592
Epoch: 59, training loss: 0.21712827883116115
Epoch: 60, training loss: 0.2113164328829091
Epoch: 61, training loss: 0.21512543418277055
Epoch: 62, training loss: 0.20870730210283533
Epoch: 63, training loss: 0.2068307710764204
Epoch: 64, training loss: 0.21078668327686356
Epoch: 65, training loss: 0.20886451253889493
Epoch: 66, training loss: 0.20448182398625725
Epoch: 67, training loss: 0.20045003084068713
Epoch: 68, training loss: 0.1997144934902329
Epoch: 69, training loss: 0.19602519722171913
Epoch: 70, training loss: 0.19397855652840476
Epoch: 71, training loss: 0.19725676648603166
Epoch: 72, training loss: 0.19478603148203238
Epoch: 73, training loss: 0.19269681700332864
Epoch: 74, training loss: 0.19169696456738383
Epoch: 75, training loss: 0.19117501394280792
Epoch: 76, training loss: 0.19254736218666446
Epoch: 77, training loss: 0.19088719125237355
Epoch: 78, training loss: 0.1868091875519462
Epoch: 79, training loss: 0.18718552680943673
Epoch: 80, training loss: 0.18233877306903382
Epoch: 81, training loss: 0.18287295630191835
Epoch: 82, training loss: 0.1839113072494
Epoch: 83, training loss: 0.18236676094013532
Epoch: 84, training loss: 0.17979463386248495
Epoch: 85, training loss: 0.1772301368934322
Epoch: 86, training loss: 0.17948323033873462
Epoch: 87, training loss: 0.1748300563492036
Epoch: 88, training loss: 0.17674173745121913
Epoch: 89, training loss: 0.17538322220486574
Epoch: 90, training loss: 0.1796814055999588
Epoch: 91, training loss: 0.17174391626339203
Epoch: 92, training loss: 0.17312541847697976
Epoch: 93, training loss: 0.1712218458679097
Epoch: 94, training loss: 0.16847881996717254
Epoch: 95, training loss: 0.17151367503848483
Epoch: 96, training loss: 0.16943862681375457
Epoch: 97, training loss: 0.16537640860918684
Epoch: 98, training loss: 0.16611106822143776
Epoch: 99, training loss: 0.16824077139897403
