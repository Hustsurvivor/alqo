train LeroModelPairWise
Epoch: 0, training loss: 0.49631589078343996
Epoch: 1, training loss: 0.4126650561982831
Epoch: 2, training loss: 0.37031713473489974
Epoch: 3, training loss: 0.33679899489148907
Epoch: 4, training loss: 0.3078342940613542
Epoch: 5, training loss: 0.28387066769565095
Epoch: 6, training loss: 0.26019153583221855
Epoch: 7, training loss: 0.2407596035547274
Epoch: 8, training loss: 0.22531827221188336
Epoch: 9, training loss: 0.20723990057785777
Epoch: 10, training loss: 0.19421681772375562
Epoch: 11, training loss: 0.18019789184302665
Epoch: 12, training loss: 0.1709581633421055
Epoch: 13, training loss: 0.16240475586981898
Epoch: 14, training loss: 0.15140711183344419
Epoch: 15, training loss: 0.14344167569758087
Epoch: 16, training loss: 0.13494079439933918
Epoch: 17, training loss: 0.130474666086628
Epoch: 18, training loss: 0.12159882649954934
Epoch: 19, training loss: 0.11845297445995032
Epoch: 20, training loss: 0.11173168690179043
Epoch: 21, training loss: 0.1068226037177068
Epoch: 22, training loss: 0.10291842495586914
Epoch: 23, training loss: 0.09731420264618702
Epoch: 24, training loss: 0.09604092731760114
Epoch: 25, training loss: 0.09242366556607445
Epoch: 26, training loss: 0.08751559435749605
Epoch: 27, training loss: 0.0854193785217532
Epoch: 28, training loss: 0.08485392492740822
Epoch: 29, training loss: 0.07919357358953631
Epoch: 30, training loss: 0.07815824305156419
Epoch: 31, training loss: 0.07341242981392197
Epoch: 32, training loss: 0.07307375652902996
Epoch: 33, training loss: 0.07206140934168903
Epoch: 34, training loss: 0.06912322730877919
Epoch: 35, training loss: 0.06816355759728382
Epoch: 36, training loss: 0.06407476535724971
Epoch: 37, training loss: 0.06382611021045481
Epoch: 38, training loss: 0.06224412830505617
Epoch: 39, training loss: 0.06025660072968829
Epoch: 40, training loss: 0.05773156373934078
Epoch: 41, training loss: 0.05705979946811488
Epoch: 42, training loss: 0.058003766984319985
Epoch: 43, training loss: 0.05536528128699608
Epoch: 44, training loss: 0.052292391060419
Epoch: 45, training loss: 0.054357947183124075
Epoch: 46, training loss: 0.04857877430701542
Epoch: 47, training loss: 0.052262031830143975
Epoch: 48, training loss: 0.049231549000560905
Epoch: 49, training loss: 0.048862973681907666
Epoch: 50, training loss: 0.04548762118541496
Epoch: 51, training loss: 0.046436727517098465
Epoch: 52, training loss: 0.046826852469839565
Epoch: 53, training loss: 0.04620569315693561
Epoch: 54, training loss: 0.04351562838860687
Epoch: 55, training loss: 0.04338789433412411
Epoch: 56, training loss: 0.04308039571481388
Epoch: 57, training loss: 0.040312733353825396
Epoch: 58, training loss: 0.03990850767315806
Epoch: 59, training loss: 0.04173219939105748
Epoch: 60, training loss: 0.03928056271242142
Epoch: 61, training loss: 0.03878172943666821
Epoch: 62, training loss: 0.03935812437088441
Epoch: 63, training loss: 0.037690634141263155
Epoch: 64, training loss: 0.03809454111482215
Epoch: 65, training loss: 0.03591044776788697
Epoch: 66, training loss: 0.037515153481725086
Epoch: 67, training loss: 0.03384225564672994
Epoch: 68, training loss: 0.035762101936356594
Epoch: 69, training loss: 0.03581840195371412
Epoch: 70, training loss: 0.036092326375544805
Epoch: 71, training loss: 0.03358500344177533
Epoch: 72, training loss: 0.03360021980350951
Epoch: 73, training loss: 0.03254498761592671
Epoch: 74, training loss: 0.0323784165365029
Epoch: 75, training loss: 0.030817536010105232
Epoch: 76, training loss: 0.03203057247772232
Epoch: 77, training loss: 0.0339074215709616
Epoch: 78, training loss: 0.03048776424280254
Epoch: 79, training loss: 0.028811424428393077
Epoch: 80, training loss: 0.0326322598311892
Epoch: 81, training loss: 0.028144519920434884
Epoch: 82, training loss: 0.030878737491338272
Epoch: 83, training loss: 0.029173810188745798
Epoch: 84, training loss: 0.028256049820053745
Epoch: 85, training loss: 0.02679381194723944
Epoch: 86, training loss: 0.02814596231979813
Epoch: 87, training loss: 0.027358640439622724
Epoch: 88, training loss: 0.027179399564484275
Epoch: 89, training loss: 0.026491722533663747
Epoch: 90, training loss: 0.0273452011222423
Epoch: 91, training loss: 0.026315072195008532
Epoch: 92, training loss: 0.025650095304244492
Epoch: 93, training loss: 0.026851420760309334
Epoch: 94, training loss: 0.02605749055560729
Epoch: 95, training loss: 0.02496784915167546
Epoch: 96, training loss: 0.026114257266502773
Epoch: 97, training loss: 0.025431156240253865
Epoch: 98, training loss: 0.025530085949629334
Epoch: 99, training loss: 0.023580915982255275
