train LeroModelPairWise
Epoch: 0, training loss: 0.5090653265215752
Epoch: 1, training loss: 0.42762228994979895
Epoch: 2, training loss: 0.38693671932373613
Epoch: 3, training loss: 0.35643701846418063
Epoch: 4, training loss: 0.3269348235848746
Epoch: 5, training loss: 0.29917115330241656
Epoch: 6, training loss: 0.27520073586458205
Epoch: 7, training loss: 0.2516350457832798
Epoch: 8, training loss: 0.2315304803901887
Epoch: 9, training loss: 0.21516196346766905
Epoch: 10, training loss: 0.19834743480284228
Epoch: 11, training loss: 0.18606631859044048
Epoch: 12, training loss: 0.17171770955063778
Epoch: 13, training loss: 0.16134575170521945
Epoch: 14, training loss: 0.14950902089107398
Epoch: 15, training loss: 0.14164496428516193
Epoch: 16, training loss: 0.1337090651067008
Epoch: 17, training loss: 0.12876855826725808
Epoch: 18, training loss: 0.12071099251306945
Epoch: 19, training loss: 0.11759518111639543
Epoch: 20, training loss: 0.11183934071840697
Epoch: 21, training loss: 0.10536004388648681
Epoch: 22, training loss: 0.09914613363597365
Epoch: 23, training loss: 0.09927732952832014
Epoch: 24, training loss: 0.09213097155948287
Epoch: 25, training loss: 0.08956293023689066
Epoch: 26, training loss: 0.08806996854532664
Epoch: 27, training loss: 0.08485671970434333
Epoch: 28, training loss: 0.08268332885651038
Epoch: 29, training loss: 0.07720395467333727
Epoch: 30, training loss: 0.07697660655183744
Epoch: 31, training loss: 0.07248437590816044
Epoch: 32, training loss: 0.07355333805434613
Epoch: 33, training loss: 0.0691236159105772
Epoch: 34, training loss: 0.06817972765009245
Epoch: 35, training loss: 0.06688013613882501
Epoch: 36, training loss: 0.06399882329474439
Epoch: 37, training loss: 0.06313618166395123
Epoch: 38, training loss: 0.06091568765093618
Epoch: 39, training loss: 0.05932104819261402
Epoch: 40, training loss: 0.057829996151587806
Epoch: 41, training loss: 0.05905960710634316
Epoch: 42, training loss: 0.05339240600232785
Epoch: 43, training loss: 0.05533713528737873
Epoch: 44, training loss: 0.052703879068991814
Epoch: 45, training loss: 0.051790612668096835
Epoch: 46, training loss: 0.050348937789630975
Epoch: 47, training loss: 0.050714384359647514
Epoch: 48, training loss: 0.047676358414546975
Epoch: 49, training loss: 0.04796716266510981
Epoch: 50, training loss: 0.04759011073476825
Epoch: 51, training loss: 0.04707385998000953
Epoch: 52, training loss: 0.0431921200622767
Epoch: 53, training loss: 0.04512423783205824
Epoch: 54, training loss: 0.042939351914979496
Epoch: 55, training loss: 0.043024120134113795
Epoch: 56, training loss: 0.04030940682295357
Epoch: 57, training loss: 0.041197112194000525
Epoch: 58, training loss: 0.04009255371582139
Epoch: 59, training loss: 0.04001529121112192
Epoch: 60, training loss: 0.03946003997380936
Epoch: 61, training loss: 0.038565108404594865
Epoch: 62, training loss: 0.039832605692868076
Epoch: 63, training loss: 0.037570234551801654
Epoch: 64, training loss: 0.037499591990836745
Epoch: 65, training loss: 0.03626462518175297
Epoch: 66, training loss: 0.034315289424826145
Epoch: 67, training loss: 0.03590047150142814
Epoch: 68, training loss: 0.03568958897437451
Epoch: 69, training loss: 0.03307994324297521
Epoch: 70, training loss: 0.032887344802345786
Epoch: 71, training loss: 0.03230858927148636
Epoch: 72, training loss: 0.03326849071327067
Epoch: 73, training loss: 0.033892189082809915
Epoch: 74, training loss: 0.029206984626899708
Epoch: 75, training loss: 0.03128688162423153
Epoch: 76, training loss: 0.03196464125762973
Epoch: 77, training loss: 0.030819813105100954
Epoch: 78, training loss: 0.030003927951773215
Epoch: 79, training loss: 0.030354207192270836
Epoch: 80, training loss: 0.030555612914119235
Epoch: 81, training loss: 0.027510958357719616
Epoch: 82, training loss: 0.029800190795348337
Epoch: 83, training loss: 0.027109691430171348
Epoch: 84, training loss: 0.027446355911134413
Epoch: 85, training loss: 0.029339192614119047
Epoch: 86, training loss: 0.025950500880265792
Epoch: 87, training loss: 0.026524876190711498
Epoch: 88, training loss: 0.026587356245851557
Epoch: 89, training loss: 0.027029095281895513
Epoch: 90, training loss: 0.025994134625126
Epoch: 91, training loss: 0.025125950872877164
Epoch: 92, training loss: 0.02537559831134467
Epoch: 93, training loss: 0.024485929969174272
Epoch: 94, training loss: 0.025273151813516533
Epoch: 95, training loss: 0.024247885744103727
Epoch: 96, training loss: 0.024854554879632427
Epoch: 97, training loss: 0.022170789140343112
Epoch: 98, training loss: 0.023721821425963963
Epoch: 99, training loss: 0.025426510205487002
