train LeroModelPairWise
Epoch: 0, training loss: 0.5758499172214895
Epoch: 1, training loss: 0.48888418733353856
Epoch: 2, training loss: 0.4401639163751909
Epoch: 3, training loss: 0.4006484795531671
Epoch: 4, training loss: 0.36636191599724083
Epoch: 5, training loss: 0.3420163079486727
Epoch: 6, training loss: 0.31677925251355926
Epoch: 7, training loss: 0.29502839643077766
Epoch: 8, training loss: 0.27143200237615095
Epoch: 9, training loss: 0.25683791890829355
Epoch: 10, training loss: 0.2428730748138632
Epoch: 11, training loss: 0.23046527915352402
Epoch: 12, training loss: 0.2161958747229054
Epoch: 13, training loss: 0.20410601151136012
Epoch: 14, training loss: 0.1966003865533826
Epoch: 15, training loss: 0.18836240158464929
Epoch: 16, training loss: 0.17815748515668803
Epoch: 17, training loss: 0.1759268222920266
Epoch: 18, training loss: 0.1611912901147142
Epoch: 19, training loss: 0.16348092001347037
Epoch: 20, training loss: 0.1566349546173978
Epoch: 21, training loss: 0.14554174534596362
Epoch: 22, training loss: 0.1465132082694043
Epoch: 23, training loss: 0.13830451265157734
Epoch: 24, training loss: 0.1364296913893244
Epoch: 25, training loss: 0.13375604228448248
Epoch: 26, training loss: 0.12556237075446583
Epoch: 27, training loss: 0.12161909290005549
Epoch: 28, training loss: 0.12213031896621693
Epoch: 29, training loss: 0.1171143671383138
Epoch: 30, training loss: 0.11842004249847497
Epoch: 31, training loss: 0.11491454858297608
Epoch: 32, training loss: 0.11190466088109056
Epoch: 33, training loss: 0.10442289478096037
Epoch: 34, training loss: 0.10842921264669537
Epoch: 35, training loss: 0.10008948231576262
Epoch: 36, training loss: 0.09159179409858219
Epoch: 37, training loss: 0.10119301009915471
Epoch: 38, training loss: 0.09742351763667094
Epoch: 39, training loss: 0.08974624300516186
Epoch: 40, training loss: 0.09343081589732942
Epoch: 41, training loss: 0.09695434957143811
Epoch: 42, training loss: 0.08555165090260884
Epoch: 43, training loss: 0.08959027615427742
Epoch: 44, training loss: 0.09160946771129465
Epoch: 45, training loss: 0.09171300376717843
Epoch: 46, training loss: 0.08455732581363863
Epoch: 47, training loss: 0.08409090176297408
Epoch: 48, training loss: 0.08306781985411357
Epoch: 49, training loss: 0.07888858974570089
Epoch: 50, training loss: 0.07421220575838723
Epoch: 51, training loss: 0.0816647497935017
Epoch: 52, training loss: 0.07770017288822476
Epoch: 53, training loss: 0.07667796709980615
Epoch: 54, training loss: 0.07552878466751313
Epoch: 55, training loss: 0.07669566502436005
Epoch: 56, training loss: 0.07574123577293793
Epoch: 57, training loss: 0.06643058505953775
Epoch: 58, training loss: 0.06778013931826217
Epoch: 59, training loss: 0.07355259974532771
Epoch: 60, training loss: 0.07398912899275256
Epoch: 61, training loss: 0.07318056506768428
Epoch: 62, training loss: 0.06912473077561782
Epoch: 63, training loss: 0.0677449488100898
Epoch: 64, training loss: 0.06833244916850097
Epoch: 65, training loss: 0.0666211901235078
Epoch: 66, training loss: 0.0670576875739055
Epoch: 67, training loss: 0.06953594202705908
Epoch: 68, training loss: 0.06443415891998881
Epoch: 69, training loss: 0.05600232706830425
Epoch: 70, training loss: 0.06078600431546101
Epoch: 71, training loss: 0.06581001183282073
Epoch: 72, training loss: 0.0593206274969811
Epoch: 73, training loss: 0.06268949355929795
Epoch: 74, training loss: 0.06094602828172857
Epoch: 75, training loss: 0.06281864666581453
Epoch: 76, training loss: 0.06036276524361409
Epoch: 77, training loss: 0.055986510068649124
Epoch: 78, training loss: 0.05810312940758547
Epoch: 79, training loss: 0.05867808093684248
Epoch: 80, training loss: 0.05691194985563796
Epoch: 81, training loss: 0.05622342944305837
Epoch: 82, training loss: 0.05978547830882761
Epoch: 83, training loss: 0.05286643517460985
Epoch: 84, training loss: 0.05252083165644607
Epoch: 85, training loss: 0.05127697765714587
Epoch: 86, training loss: 0.06201635029323405
Epoch: 87, training loss: 0.04590962889734303
Epoch: 88, training loss: 0.05562523426006809
Epoch: 89, training loss: 0.05434475971459329
Epoch: 90, training loss: 0.052125490799111975
Epoch: 91, training loss: 0.05907147550410965
Epoch: 92, training loss: 0.05254370074699874
Epoch: 93, training loss: 0.0471426101496912
Epoch: 94, training loss: 0.05046470041791627
Epoch: 95, training loss: 0.05226035480646137
Epoch: 96, training loss: 0.04624547909167062
Epoch: 97, training loss: 0.05160342622383404
Epoch: 98, training loss: 0.05151992824117774
Epoch: 99, training loss: 0.05130087733270397
